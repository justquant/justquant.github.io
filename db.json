{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/images/spark-tuning-f1.png","path":"images/spark-tuning-f1.png","modified":1,"renderable":0},{"_id":"source/images/stock_macd_600116_20161121.jpg","path":"images/stock_macd_600116_20161121.jpg","modified":1,"renderable":0},{"_id":"source/images/spark-tuning2-f1.png","path":"images/spark-tuning2-f1.png","modified":1,"renderable":0},{"_id":"themes/light/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/light/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":1,"renderable":1},{"_id":"themes/light/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/light/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/light/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/light/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/light/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/light/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/light/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/light/source/js/jquery.imagesloaded.min.js","path":"js/jquery.imagesloaded.min.js","modified":1,"renderable":1},{"_id":"themes/light/source/js/gallery.js","path":"js/gallery.js","modified":1,"renderable":1},{"_id":"themes/light/source/css/font/fontawesome-webfont.eot","path":"css/font/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/light/source/css/font/fontawesome-webfont.woff","path":"css/font/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/light/source/css/font/fontawesome-webfont.svg","path":"css/font/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"themes/light/source/css/font/fontawesome-webfont.ttf","path":"css/font/fontawesome-webfont.ttf","modified":1,"renderable":1}],"Cache":[{"_id":"themes/light/LICENSE","hash":"c6f301bc722f0af3a55267a36c1c147aeddc6e46","modified":1479694263376},{"_id":"themes/light/README.md","hash":"aa189c7ff03c60d8fceb009f5fca1a61d8a0ecdf","modified":1479694263376},{"_id":"themes/light/_config.yml","hash":"54873f9af5e1d1c802fcd7c642c4187f1f04e6b9","modified":1479694263376},{"_id":"source/_drafts/macd-rise-pattern-1.md","hash":"bae4fb22b14015f07fdb85d3afbff5f395dc8123","modified":1479795843000},{"_id":"source/_posts/cli-construction-tools.md","hash":"f6b89b879f5af0716bb0c726952f4211d2787bf0","modified":1479697999000},{"_id":"source/_posts/hello-world.md","hash":"3ef0afc093299ded5f0594d05ecab28026f28851","modified":1479697000301},{"_id":"source/_posts/scikitleanr-preparing-data.md","hash":"ae088edefb623c973430b97a9f84a4e9683b2ea0","modified":1479795901333},{"_id":"source/_posts/spark-performance-tuning.md","hash":"e54f6f3fff0338265c744be649f42a013c3f054b","modified":1479696988322},{"_id":"source/_posts/spark-resources.md","hash":"2a252229ad864c203fa0bc35796fd6728c17019d","modified":1479698145000},{"_id":"source/images/spark-tuning-f1.png","hash":"566627b866722d7ab629ab669a337102da1f7c80","modified":1479694263316},{"_id":"source/images/stock_macd_600116_20161121.jpg","hash":"1d18a4d6cc26961729dd25cddb87444085624d21","modified":1479704703523},{"_id":"themes/light/languages/de.yml","hash":"e076c7f2eb29ebcfb04d94861bf3063c4b08078c","modified":1479694263376},{"_id":"themes/light/languages/default.yml","hash":"fd7397be7789b43c1c163ab4faf106318811c2a8","modified":1479694263376},{"_id":"themes/light/languages/es.yml","hash":"de273af604b27812cfd4195e7b7f28ceff2734b3","modified":1479694263376},{"_id":"themes/light/languages/lt.yml","hash":"8826ef5b3911e094f8a118d8db981532d0919bb6","modified":1479694263376},{"_id":"themes/light/languages/no.yml","hash":"bf11017d77f64fbafb9c99ac219d076b20d53afc","modified":1479694263376},{"_id":"themes/light/languages/pl.yml","hash":"3f36d08e84a85651bf777cec0752193057c08430","modified":1479694263376},{"_id":"themes/light/languages/ru.yml","hash":"35aadf8fdd28aaff8a1c8f50e80201dcf8ce0604","modified":1479694263376},{"_id":"themes/light/languages/zh-CN.yml","hash":"ca0118e9081b54cc0fca8596660bd6acf4c0308f","modified":1479694263376},{"_id":"themes/light/languages/zh-TW.yml","hash":"6141b4c7a094c74bd9df7c08908d92b561c1a0c0","modified":1479694263386},{"_id":"themes/light/layout/archive.ejs","hash":"a18842e3d719fe3ca9b977a6995f8facc75c8673","modified":1479694263396},{"_id":"themes/light/layout/category.ejs","hash":"9b740fc33f6f028df60f0bc4312bf3ebd03aa8ea","modified":1479694263396},{"_id":"themes/light/layout/index.ejs","hash":"e569d8fe0741a24efb89e44781f9e616da17e036","modified":1479694263396},{"_id":"themes/light/layout/layout.ejs","hash":"8c1526f377aec01cf43be017834a3683d21b2ea9","modified":1479694263396},{"_id":"themes/light/layout/page.ejs","hash":"70cbc9854655773cc6ba84eecaaf330fed430465","modified":1479694263396},{"_id":"themes/light/layout/post.ejs","hash":"70cbc9854655773cc6ba84eecaaf330fed430465","modified":1479694263396},{"_id":"themes/light/layout/tag.ejs","hash":"45150a2365768b6b67880193c9264ad2bb4814db","modified":1479694263396},{"_id":"source/images/spark-tuning2-f1.png","hash":"e51f9dae3c981fef9e2b4d1ed8f4b0fb7b611e7d","modified":1479694263316},{"_id":"themes/light/layout/_partial/after_footer.ejs","hash":"be0905e9fb3730d63685b5db579875538a92de95","modified":1479694263386},{"_id":"themes/light/layout/_partial/archive.ejs","hash":"7e4f7c2909b1b90241424ea2ff8e7b4761d8360f","modified":1479694263386},{"_id":"themes/light/layout/_partial/comment.ejs","hash":"be7d9849855f2bb31e626db88b49ac1d87446e21","modified":1479694263386},{"_id":"themes/light/layout/_partial/article.ejs","hash":"508fb3aaac2b68e6f24bd5259a0684e23f46fe37","modified":1479694263386},{"_id":"themes/light/layout/_partial/footer.ejs","hash":"1deac5914b2fc93b271732fd4d5cbd0a6f78875f","modified":1479694263386},{"_id":"themes/light/layout/_partial/google_analytics.ejs","hash":"7cf0d1f93051bda510d49dab7f684b9d7c6ba58f","modified":1479694263386},{"_id":"themes/light/layout/_partial/head.ejs","hash":"5e110e4b0a2a896a073dfc7739220025b02a4077","modified":1479694263386},{"_id":"themes/light/layout/_partial/header.ejs","hash":"224ea7f0fccc29418583a5c59497a8ece0073301","modified":1479694263386},{"_id":"themes/light/layout/_partial/pagination.ejs","hash":"1206b630a07444e8744365f14ddb26095c925ae1","modified":1479694263386},{"_id":"themes/light/layout/_partial/facebook_comment.ejs","hash":"3fdc1d0ce9177825e7417635fbc545a35d528d04","modified":1479694263386},{"_id":"themes/light/layout/_partial/sidebar.ejs","hash":"caf351797a18d03d8ee945ceb9f83785c50c09f9","modified":1479694263396},{"_id":"themes/light/layout/_widget/category.ejs","hash":"8a2b90dc29661371f060f710668929c3588e15e4","modified":1479694263396},{"_id":"themes/light/layout/_widget/recent_posts.ejs","hash":"f17d2cb69034acabea4df54f301f80812e7b84a8","modified":1479694263396},{"_id":"themes/light/layout/_widget/search.ejs","hash":"55c707f3aa7453c305c41898ad22556edd213830","modified":1479694263396},{"_id":"themes/light/layout/_widget/tag.ejs","hash":"1914db78bea49c333067d79fe7ad9567d2b08d00","modified":1479694263396},{"_id":"themes/light/layout/_widget/tagcloud.ejs","hash":"a236c86481196ae43206e056ba78cec14f1ac014","modified":1479694263396},{"_id":"themes/light/source/css/style.styl","hash":"c03b2520e4a85b981e29516cadc0a365e6500e3d","modified":1479694263416},{"_id":"themes/light/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1479694263416},{"_id":"themes/light/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1479694263416},{"_id":"themes/light/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1479694263416},{"_id":"themes/light/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1479694263416},{"_id":"themes/light/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1479694263416},{"_id":"themes/light/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1479694263416},{"_id":"themes/light/source/fancybox/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1479694263416},{"_id":"themes/light/source/fancybox/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1479694263416},{"_id":"themes/light/source/js/jquery.imagesloaded.min.js","hash":"4109837b1f6477bacc6b095a863b1b95b1b3693f","modified":1479694263416},{"_id":"themes/light/source/js/gallery.js","hash":"f8a4ba7fb8349cca374a3c69fff9b2bf21f742ed","modified":1479694263416},{"_id":"themes/light/source/css/_base/utils.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1479694263406},{"_id":"themes/light/layout/_partial/post/category.ejs","hash":"be740939c5c2d4ffdbed9557b4e63a590058b476","modified":1479694263386},{"_id":"themes/light/layout/_partial/post/gallery.ejs","hash":"fafc2501d7e65983b0f5c2b58151ca12e57c0574","modified":1479694263386},{"_id":"themes/light/layout/_partial/post/share.ejs","hash":"24c04b319f1b19e887c42db961b90a7e0ab26fdc","modified":1479694263386},{"_id":"themes/light/layout/_partial/post/tag.ejs","hash":"095418df66a27a28cbab16d7cb0d16001b0e23f1","modified":1479694263386},{"_id":"themes/light/layout/_partial/post/title.ejs","hash":"d7fbc575d35ae68f9045a382c651450e4131f335","modified":1479694263396},{"_id":"themes/light/source/css/_base/layout.styl","hash":"1b58c21aa48a8f9f7f811af681ac182dd058e23d","modified":1479694263406},{"_id":"themes/light/source/css/_base/variable.styl","hash":"6f3ad13e49634dae8cd992bbd598f5ff0b39a816","modified":1479694263406},{"_id":"themes/light/source/css/_partial/archive.styl","hash":"072e9b8c5ee9acf95ac7cce9c34706d41e412229","modified":1479694263406},{"_id":"themes/light/source/css/_partial/article.styl","hash":"c40dea0a6035628dd299cee299d8a6d2abf20d8b","modified":1479694263406},{"_id":"themes/light/source/css/_partial/comment.styl","hash":"e7f8c085bfa8c26afc4b2fbc9f2092f4f07aef34","modified":1479694263406},{"_id":"themes/light/source/css/_partial/footer.styl","hash":"1757872dbdbd09295a625f13e356aa798a8bb308","modified":1479694263406},{"_id":"themes/light/source/css/_partial/header.styl","hash":"50d36fe0c803cbba69dd57493611466e4d72156e","modified":1479694263406},{"_id":"themes/light/source/css/_partial/index.styl","hash":"7a8c0ec6ab99a9f8e00c9687aca29d31752424a2","modified":1479694263406},{"_id":"themes/light/source/css/_partial/syntax.styl","hash":"400335f01229ed02e62110ba90312adb78b84ff5","modified":1479694263406},{"_id":"themes/light/source/css/_partial/sidebar.styl","hash":"a8bf5237d7d2fba66988cfb85a3ae218be8709ae","modified":1479694263406},{"_id":"themes/light/source/css/font/fontawesome-webfont.eot","hash":"d775f599ff3f23be082e6a9604b4898718923a37","modified":1479694263406},{"_id":"themes/light/source/css/font/fontawesome-webfont.woff","hash":"0612cddf2f835cceffccc88fd194f97367d0b024","modified":1479694263416},{"_id":"themes/light/source/css/font/fontawesome-webfont.svg","hash":"d162419c91b8bab3a4fd327c933a0fcf3799c251","modified":1479694263406},{"_id":"themes/light/source/css/font/fontawesome-webfont.ttf","hash":"a9468f6a1fe965fbcaf5a1bd6c11705e2fc5f84c","modified":1479694263416},{"_id":"public/2016/11/22/scikitleanr-preparing-data/index.html","hash":"3dc91ff45e9f335ab65698514cf921f780461c12","modified":1479795951112},{"_id":"public/2016/11/21/cli-construction-tools/index.html","hash":"c55eb6eda0fd3c5f492d0c83942510de39693f74","modified":1479795951122},{"_id":"public/2016/11/21/spark-resources/index.html","hash":"bc4ad0583ea21b84eda68ac44a17c1d00d874fd0","modified":1479795951132},{"_id":"public/2016/11/18/hello-world/index.html","hash":"6eb4bf186436d5ea5fb3740d3d8c90bbdd9115d5","modified":1479795951132},{"_id":"public/archives/index.html","hash":"bd2aaa2d1c37638e28b487357f3e4039fb119c40","modified":1479795951132},{"_id":"public/archives/2016/index.html","hash":"a9e91a493b4504d65e804f9b024fe99f79790a5d","modified":1479795951132},{"_id":"public/archives/2016/11/index.html","hash":"776898e36d188d49660519f9af0075baf0db7f69","modified":1479795951132},{"_id":"public/tags/Tool/index.html","hash":"caca48768a5b2bde3b2822e79dccf4592d65572f","modified":1479795951132},{"_id":"public/tags/python/index.html","hash":"475335226f8d8cdf5499895735a2813ac3335ba4","modified":1479795951132},{"_id":"public/tags/scikit-learn/index.html","hash":"f9f05c6afe71252a2cb77ba2fb690b5cef80e8e8","modified":1479795951132},{"_id":"public/2016/11/20/spark-performance-tuning/index.html","hash":"dc8db710a73f459e4a380df57719befea64320ae","modified":1479795951132},{"_id":"public/index.html","hash":"3fe346d3420b50ee625346a5972f9483486f7645","modified":1479795951132},{"_id":"public/tags/机器学习/index.html","hash":"36334ebfde104442aea90d634af8d75a63e5bbdb","modified":1479795951142},{"_id":"public/tags/Spark/index.html","hash":"13224105b33ac672f2fa66b860874dd58948018d","modified":1479795951142},{"_id":"public/tags/Resource/index.html","hash":"3a16fcce36ba339de84c3b691000d95f6206bf96","modified":1479795951142},{"_id":"public/images/spark-tuning-f1.png","hash":"566627b866722d7ab629ab669a337102da1f7c80","modified":1479795951142},{"_id":"public/images/stock_macd_600116_20161121.jpg","hash":"1d18a4d6cc26961729dd25cddb87444085624d21","modified":1479795951142},{"_id":"public/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1479795951142},{"_id":"public/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1479795951142},{"_id":"public/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1479795951142},{"_id":"public/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1479795951142},{"_id":"public/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1479795951142},{"_id":"public/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1479795951142},{"_id":"public/css/font/fontawesome-webfont.woff","hash":"0612cddf2f835cceffccc88fd194f97367d0b024","modified":1479795951142},{"_id":"public/css/font/fontawesome-webfont.eot","hash":"d775f599ff3f23be082e6a9604b4898718923a37","modified":1479795951142},{"_id":"public/images/spark-tuning2-f1.png","hash":"e51f9dae3c981fef9e2b4d1ed8f4b0fb7b611e7d","modified":1479795951988},{"_id":"public/css/font/fontawesome-webfont.svg","hash":"d162419c91b8bab3a4fd327c933a0fcf3799c251","modified":1479795951998},{"_id":"public/css/font/fontawesome-webfont.ttf","hash":"a9468f6a1fe965fbcaf5a1bd6c11705e2fc5f84c","modified":1479795951998},{"_id":"public/css/style.css","hash":"d9cc77a18d5014e515cfc3debac6aa8c484a1e85","modified":1479795951998},{"_id":"public/fancybox/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1479795951998},{"_id":"public/js/jquery.imagesloaded.min.js","hash":"4109837b1f6477bacc6b095a863b1b95b1b3693f","modified":1479795951998},{"_id":"public/js/gallery.js","hash":"f8a4ba7fb8349cca374a3c69fff9b2bf21f742ed","modified":1479795951998},{"_id":"public/fancybox/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1479795951998}],"Category":[],"Data":[],"Page":[],"Post":[{"title":"MACD起涨模式-快慢线黏连","_content":"\nMACD被誉为股票技术分析中的黄金指标。本文主要描述在日常观察中发现的一种MACD的形态模式。在日常看盘中，我发现这种模式出现够，中短线大概率会出现上涨，当然幅度无法确定。\n\n任何经验都需要被量化和验证。下一步应该通过统计的方式计算出模式的成功概率。如果能够通过机器学习转化为机器能够识别的模式，那就更完美了。\n\n# 模式\n\n## 形态描述\n\n- MACD的快线（DIFF）和慢线（DEA）黏连在一起。黏连就是DIFF和MACD的差值（柱状线的长度，正负均可）的绝对值非常小，看起来像一条线。\n- 时间持续两个星期到一个月。\n- 黏连后MACD突然发散，快线抬头向上，柱状线为红柱并且长度是之前平均长度的3倍以上\n- 发散时收中阳线或者大阳线\n\n\n## 行为分析\n\nMACD长时间黏连，代表股价正在蓄势整理选择方向\nMACD突然发散，且收红柱，代表方向选择为上升。\n发散的当天收中阳线或者大阳线，\n\n发散的同时或者后一两天，应该伴随着放量。均线逐步为多头排列\n\n## 其它辅助指标\n\n应该观察股价所处的阶段。按照波浪理论，出现黏连模式，一般为第二、四浪调整浪。\n\n在MACD横盘期间，股价应该横盘，么有出现大涨和大跌。\n\n## 例子\n\n![三峡水利2016年8月15日到2016年9月6日](/images/stock_macd_600116_20161121.jpg)\n\n横盘时间为17个交易日。然后放量上涨。\n\n# 统计数据\n\n//TBD\n\n# 编程实现？\n\n//TBD","source":"_drafts/macd-rise-pattern-1.md","raw":"---\ntitle: MACD起涨模式-快慢线黏连\ntags: \n - 股票\n - MACD\n---\n\nMACD被誉为股票技术分析中的黄金指标。本文主要描述在日常观察中发现的一种MACD的形态模式。在日常看盘中，我发现这种模式出现够，中短线大概率会出现上涨，当然幅度无法确定。\n\n任何经验都需要被量化和验证。下一步应该通过统计的方式计算出模式的成功概率。如果能够通过机器学习转化为机器能够识别的模式，那就更完美了。\n\n# 模式\n\n## 形态描述\n\n- MACD的快线（DIFF）和慢线（DEA）黏连在一起。黏连就是DIFF和MACD的差值（柱状线的长度，正负均可）的绝对值非常小，看起来像一条线。\n- 时间持续两个星期到一个月。\n- 黏连后MACD突然发散，快线抬头向上，柱状线为红柱并且长度是之前平均长度的3倍以上\n- 发散时收中阳线或者大阳线\n\n\n## 行为分析\n\nMACD长时间黏连，代表股价正在蓄势整理选择方向\nMACD突然发散，且收红柱，代表方向选择为上升。\n发散的当天收中阳线或者大阳线，\n\n发散的同时或者后一两天，应该伴随着放量。均线逐步为多头排列\n\n## 其它辅助指标\n\n应该观察股价所处的阶段。按照波浪理论，出现黏连模式，一般为第二、四浪调整浪。\n\n在MACD横盘期间，股价应该横盘，么有出现大涨和大跌。\n\n## 例子\n\n![三峡水利2016年8月15日到2016年9月6日](/images/stock_macd_600116_20161121.jpg)\n\n横盘时间为17个交易日。然后放量上涨。\n\n# 统计数据\n\n//TBD\n\n# 编程实现？\n\n//TBD","slug":"macd-rise-pattern-1","published":0,"date":"2016-11-21T03:23:35.538Z","updated":"2016-11-22T06:24:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civt4av140000s4kby9pmg6jv","content":"<p>MACD被誉为股票技术分析中的黄金指标。本文主要描述在日常观察中发现的一种MACD的形态模式。在日常看盘中，我发现这种模式出现够，中短线大概率会出现上涨，当然幅度无法确定。</p>\n<p>任何经验都需要被量化和验证。下一步应该通过统计的方式计算出模式的成功概率。如果能够通过机器学习转化为机器能够识别的模式，那就更完美了。</p>\n<h1 id=\"模式\"><a href=\"#模式\" class=\"headerlink\" title=\"模式\"></a>模式</h1><h2 id=\"形态描述\"><a href=\"#形态描述\" class=\"headerlink\" title=\"形态描述\"></a>形态描述</h2><ul>\n<li>MACD的快线（DIFF）和慢线（DEA）黏连在一起。黏连就是DIFF和MACD的差值（柱状线的长度，正负均可）的绝对值非常小，看起来像一条线。</li>\n<li>时间持续两个星期到一个月。</li>\n<li>黏连后MACD突然发散，快线抬头向上，柱状线为红柱并且长度是之前平均长度的3倍以上</li>\n<li>发散时收中阳线或者大阳线</li>\n</ul>\n<h2 id=\"行为分析\"><a href=\"#行为分析\" class=\"headerlink\" title=\"行为分析\"></a>行为分析</h2><p>MACD长时间黏连，代表股价正在蓄势整理选择方向<br>MACD突然发散，且收红柱，代表方向选择为上升。<br>发散的当天收中阳线或者大阳线，</p>\n<p>发散的同时或者后一两天，应该伴随着放量。均线逐步为多头排列</p>\n<h2 id=\"其它辅助指标\"><a href=\"#其它辅助指标\" class=\"headerlink\" title=\"其它辅助指标\"></a>其它辅助指标</h2><p>应该观察股价所处的阶段。按照波浪理论，出现黏连模式，一般为第二、四浪调整浪。</p>\n<p>在MACD横盘期间，股价应该横盘，么有出现大涨和大跌。</p>\n<h2 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h2><p><img src=\"/images/stock_macd_600116_20161121.jpg\" alt=\"三峡水利2016年8月15日到2016年9月6日\"></p>\n<p>横盘时间为17个交易日。然后放量上涨。</p>\n<h1 id=\"统计数据\"><a href=\"#统计数据\" class=\"headerlink\" title=\"统计数据\"></a>统计数据</h1><p>//TBD</p>\n<h1 id=\"编程实现？\"><a href=\"#编程实现？\" class=\"headerlink\" title=\"编程实现？\"></a>编程实现？</h1><p>//TBD</p>\n","excerpt":"","more":"<p>MACD被誉为股票技术分析中的黄金指标。本文主要描述在日常观察中发现的一种MACD的形态模式。在日常看盘中，我发现这种模式出现够，中短线大概率会出现上涨，当然幅度无法确定。</p>\n<p>任何经验都需要被量化和验证。下一步应该通过统计的方式计算出模式的成功概率。如果能够通过机器学习转化为机器能够识别的模式，那就更完美了。</p>\n<h1 id=\"模式\"><a href=\"#模式\" class=\"headerlink\" title=\"模式\"></a>模式</h1><h2 id=\"形态描述\"><a href=\"#形态描述\" class=\"headerlink\" title=\"形态描述\"></a>形态描述</h2><ul>\n<li>MACD的快线（DIFF）和慢线（DEA）黏连在一起。黏连就是DIFF和MACD的差值（柱状线的长度，正负均可）的绝对值非常小，看起来像一条线。</li>\n<li>时间持续两个星期到一个月。</li>\n<li>黏连后MACD突然发散，快线抬头向上，柱状线为红柱并且长度是之前平均长度的3倍以上</li>\n<li>发散时收中阳线或者大阳线</li>\n</ul>\n<h2 id=\"行为分析\"><a href=\"#行为分析\" class=\"headerlink\" title=\"行为分析\"></a>行为分析</h2><p>MACD长时间黏连，代表股价正在蓄势整理选择方向<br>MACD突然发散，且收红柱，代表方向选择为上升。<br>发散的当天收中阳线或者大阳线，</p>\n<p>发散的同时或者后一两天，应该伴随着放量。均线逐步为多头排列</p>\n<h2 id=\"其它辅助指标\"><a href=\"#其它辅助指标\" class=\"headerlink\" title=\"其它辅助指标\"></a>其它辅助指标</h2><p>应该观察股价所处的阶段。按照波浪理论，出现黏连模式，一般为第二、四浪调整浪。</p>\n<p>在MACD横盘期间，股价应该横盘，么有出现大涨和大跌。</p>\n<h2 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h2><p><img src=\"/images/stock_macd_600116_20161121.jpg\" alt=\"三峡水利2016年8月15日到2016年9月6日\"></p>\n<p>横盘时间为17个交易日。然后放量上涨。</p>\n<h1 id=\"统计数据\"><a href=\"#统计数据\" class=\"headerlink\" title=\"统计数据\"></a>统计数据</h1><p>//TBD</p>\n<h1 id=\"编程实现？\"><a href=\"#编程实现？\" class=\"headerlink\" title=\"编程实现？\"></a>编程实现？</h1><p>//TBD</p>\n"},{"title":"CLI 参数解析器","date":"2016-11-21T03:00:20.000Z","_content":"\n最近在开发一个Spark程序，需要解析自定义的参数。经过一番搜索，选定了两个工具：\n\n- [Apache Commons CLI](https://commons.apache.org/proper/commons-cli/)\n- [Scopt, Simple scala command line options parsing](https://github.com/scopt/scopt)\n\n从官方介绍来看，Apache Commons CLI功能比较强大，可以支持丰富的语法。但最终我们还是选定了SCOPT，主要是因为它是scala写的，而且我们只需要一个简单的解析器。\n\n这边文章主要介绍SCOPT。Apache Commons CLI请参看其官网。\n\n\n\n","source":"_posts/cli-construction-tools.md","raw":"---\ntitle: CLI 参数解析器\ndate: 2016-11-21 11:00:20\ntags: [Tool]\n---\n\n最近在开发一个Spark程序，需要解析自定义的参数。经过一番搜索，选定了两个工具：\n\n- [Apache Commons CLI](https://commons.apache.org/proper/commons-cli/)\n- [Scopt, Simple scala command line options parsing](https://github.com/scopt/scopt)\n\n从官方介绍来看，Apache Commons CLI功能比较强大，可以支持丰富的语法。但最终我们还是选定了SCOPT，主要是因为它是scala写的，而且我们只需要一个简单的解析器。\n\n这边文章主要介绍SCOPT。Apache Commons CLI请参看其官网。\n\n\n\n","slug":"cli-construction-tools","published":1,"updated":"2016-11-21T03:13:19.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civt4av1e0001s4kbmly4mds2","content":"<p>最近在开发一个Spark程序，需要解析自定义的参数。经过一番搜索，选定了两个工具：</p>\n<ul>\n<li><a href=\"https://commons.apache.org/proper/commons-cli/\" target=\"_blank\" rel=\"external\">Apache Commons CLI</a></li>\n<li><a href=\"https://github.com/scopt/scopt\" target=\"_blank\" rel=\"external\">Scopt, Simple scala command line options parsing</a></li>\n</ul>\n<p>从官方介绍来看，Apache Commons CLI功能比较强大，可以支持丰富的语法。但最终我们还是选定了SCOPT，主要是因为它是scala写的，而且我们只需要一个简单的解析器。</p>\n<p>这边文章主要介绍SCOPT。Apache Commons CLI请参看其官网。</p>\n","excerpt":"","more":"<p>最近在开发一个Spark程序，需要解析自定义的参数。经过一番搜索，选定了两个工具：</p>\n<ul>\n<li><a href=\"https://commons.apache.org/proper/commons-cli/\">Apache Commons CLI</a></li>\n<li><a href=\"https://github.com/scopt/scopt\">Scopt, Simple scala command line options parsing</a></li>\n</ul>\n<p>从官方介绍来看，Apache Commons CLI功能比较强大，可以支持丰富的语法。但最终我们还是选定了SCOPT，主要是因为它是scala写的，而且我们只需要一个简单的解析器。</p>\n<p>这边文章主要介绍SCOPT。Apache Commons CLI请参看其官网。</p>\n"},{"title":"你好，世界","date":"2016-11-18T02:44:15.000Z","_content":"\n在我学习每一门编程语言，第一个程序都是Hello World! 当我决定重新开始写博客，我想第一遍文章也是 **你好，世界**。\n\n为什么想写博客？想安静。想回忆，想分享。\n\n想静下来。常常有一种感觉，就是明天昨天发生的事情，却只有一个模糊的影响，很多细节都记不清楚。生活的脚步匆匆，灵魂一直在奔忙。\n\n我想，我需要慢下来。而写作，在构思的过程中，能让我的思绪静下来，让我收获宁静。\n\n想回忆，就是想着，有一天自己回过头去看看自己走过的路，有一个地方，帮我存着。\n\n想分享。自己在IT领域工作已经有10个年头了，虽然不是什么大牛，却多多少少一些经验可以去分享。只要能惠及一个人，也就知足了。\n\n找了很多博客例如CSDN等，最后还是自己搭建。不求很多人知道，我只想有那么一个角落，让我自己静静的与自己对话。\n\n就这样，我相遇了Hexo。感谢开源世界哪些默默奉献的人，你们的分享这个世界更美好。\n\n最后为什么把博客取名为Justquant, 因为我有一个梦想，或许是一个白日梦。就是能成为一名宽客，养一个机器人，让它为我在金融市场挖矿，而我，就去环游世界。\n\n**感谢[Hexo](https://hexo.io/)! 感谢[Github](https://github.com/)**\n\n\n","source":"_posts/hello-world.md","raw":"---\ntitle: 你好，世界\ndate: 2016-11-18 10:44:15\n---\n\n在我学习每一门编程语言，第一个程序都是Hello World! 当我决定重新开始写博客，我想第一遍文章也是 **你好，世界**。\n\n为什么想写博客？想安静。想回忆，想分享。\n\n想静下来。常常有一种感觉，就是明天昨天发生的事情，却只有一个模糊的影响，很多细节都记不清楚。生活的脚步匆匆，灵魂一直在奔忙。\n\n我想，我需要慢下来。而写作，在构思的过程中，能让我的思绪静下来，让我收获宁静。\n\n想回忆，就是想着，有一天自己回过头去看看自己走过的路，有一个地方，帮我存着。\n\n想分享。自己在IT领域工作已经有10个年头了，虽然不是什么大牛，却多多少少一些经验可以去分享。只要能惠及一个人，也就知足了。\n\n找了很多博客例如CSDN等，最后还是自己搭建。不求很多人知道，我只想有那么一个角落，让我自己静静的与自己对话。\n\n就这样，我相遇了Hexo。感谢开源世界哪些默默奉献的人，你们的分享这个世界更美好。\n\n最后为什么把博客取名为Justquant, 因为我有一个梦想，或许是一个白日梦。就是能成为一名宽客，养一个机器人，让它为我在金融市场挖矿，而我，就去环游世界。\n\n**感谢[Hexo](https://hexo.io/)! 感谢[Github](https://github.com/)**\n\n\n","slug":"hello-world","published":1,"updated":"2016-11-21T02:56:40.301Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civt4av1e0003s4kbgbeqa4q4","content":"<p>在我学习每一门编程语言，第一个程序都是Hello World! 当我决定重新开始写博客，我想第一遍文章也是 <strong>你好，世界</strong>。</p>\n<p>为什么想写博客？想安静。想回忆，想分享。</p>\n<p>想静下来。常常有一种感觉，就是明天昨天发生的事情，却只有一个模糊的影响，很多细节都记不清楚。生活的脚步匆匆，灵魂一直在奔忙。</p>\n<p>我想，我需要慢下来。而写作，在构思的过程中，能让我的思绪静下来，让我收获宁静。</p>\n<p>想回忆，就是想着，有一天自己回过头去看看自己走过的路，有一个地方，帮我存着。</p>\n<p>想分享。自己在IT领域工作已经有10个年头了，虽然不是什么大牛，却多多少少一些经验可以去分享。只要能惠及一个人，也就知足了。</p>\n<p>找了很多博客例如CSDN等，最后还是自己搭建。不求很多人知道，我只想有那么一个角落，让我自己静静的与自己对话。</p>\n<p>就这样，我相遇了Hexo。感谢开源世界哪些默默奉献的人，你们的分享这个世界更美好。</p>\n<p>最后为什么把博客取名为Justquant, 因为我有一个梦想，或许是一个白日梦。就是能成为一名宽客，养一个机器人，让它为我在金融市场挖矿，而我，就去环游世界。</p>\n<p><strong>感谢<a href=\"https://hexo.io/\" target=\"_blank\" rel=\"external\">Hexo</a>! 感谢<a href=\"https://github.com/\" target=\"_blank\" rel=\"external\">Github</a></strong></p>\n","excerpt":"","more":"<p>在我学习每一门编程语言，第一个程序都是Hello World! 当我决定重新开始写博客，我想第一遍文章也是 <strong>你好，世界</strong>。</p>\n<p>为什么想写博客？想安静。想回忆，想分享。</p>\n<p>想静下来。常常有一种感觉，就是明天昨天发生的事情，却只有一个模糊的影响，很多细节都记不清楚。生活的脚步匆匆，灵魂一直在奔忙。</p>\n<p>我想，我需要慢下来。而写作，在构思的过程中，能让我的思绪静下来，让我收获宁静。</p>\n<p>想回忆，就是想着，有一天自己回过头去看看自己走过的路，有一个地方，帮我存着。</p>\n<p>想分享。自己在IT领域工作已经有10个年头了，虽然不是什么大牛，却多多少少一些经验可以去分享。只要能惠及一个人，也就知足了。</p>\n<p>找了很多博客例如CSDN等，最后还是自己搭建。不求很多人知道，我只想有那么一个角落，让我自己静静的与自己对话。</p>\n<p>就这样，我相遇了Hexo。感谢开源世界哪些默默奉献的人，你们的分享这个世界更美好。</p>\n<p>最后为什么把博客取名为Justquant, 因为我有一个梦想，或许是一个白日梦。就是能成为一名宽客，养一个机器人，让它为我在金融市场挖矿，而我，就去环游世界。</p>\n<p><strong>感谢<a href=\"https://hexo.io/\">Hexo</a>! 感谢<a href=\"https://github.com/\">Github</a></strong></p>\n"},{"title":"scikit-learn笔记——准备数据","date":"2016-11-22T06:25:01.000Z","_content":"\n> 种一棵树最好的时间，是十年前和现在\n\n终于决定踏入机器学习的世界。只为了那个梦想：养一个机器人在金融市场挖矿，然后去环游世界。\n\n选择scikit-learn，是因为python已经成为事实上的数据分析和挖掘的语言，是很多数据科学家的首选。而且scikit-learn还可以与Spark集成，感谢Databricks的工程师。\n\n参考：[Auto-scaling scikit-learn with Apache Spark](https://databricks.com/blog/2016/02/08/auto-scaling-scikit-learn-with-apache-spark.html)\n\n俗话说：兵马未动粮草先行。要学习scikit-learn，首先需要有数据。作为学习，Scikit-learn提供了三种方式获取数据。\n\n# 内部自带的数据\n\nscikit-learn包自带的数据在datasets模块当中。\n\n```python\nfrom sklearn import datasets\nimport numpy as np\n```\n在IPython中，通过输入datasets.*?会列出datasets包含的所有API。\n\n```python\nboston = d.load_boston()\nprint(boston.DESCR)\n```\n\n内部数据的接口用：datasets.load_*?()\n\n# 外部数据\n\ndatasets模块也包含了API获取外部的数据。这些API以 fetch_*? 开头。\n\n```python\nhousing = datasets.fetch_california_housing()\n```\n\n# 造数据\n\n除了已有的数据，scikit-learn还提供了丰富的API来生成少量的数据。\n\n这些接口都以datasets.make_*?开头。\n\n```python\ndatasets.make_regression(1000,10,5,2,1.0)\n```\n","source":"_posts/scikitleanr-preparing-data.md","raw":"---\ntitle: scikit-learn笔记——准备数据\ntags:\n  - python\n  - scikit-learn\n  - 机器学习\ndate: 2016-11-22 14:25:01\n---\n\n> 种一棵树最好的时间，是十年前和现在\n\n终于决定踏入机器学习的世界。只为了那个梦想：养一个机器人在金融市场挖矿，然后去环游世界。\n\n选择scikit-learn，是因为python已经成为事实上的数据分析和挖掘的语言，是很多数据科学家的首选。而且scikit-learn还可以与Spark集成，感谢Databricks的工程师。\n\n参考：[Auto-scaling scikit-learn with Apache Spark](https://databricks.com/blog/2016/02/08/auto-scaling-scikit-learn-with-apache-spark.html)\n\n俗话说：兵马未动粮草先行。要学习scikit-learn，首先需要有数据。作为学习，Scikit-learn提供了三种方式获取数据。\n\n# 内部自带的数据\n\nscikit-learn包自带的数据在datasets模块当中。\n\n```python\nfrom sklearn import datasets\nimport numpy as np\n```\n在IPython中，通过输入datasets.*?会列出datasets包含的所有API。\n\n```python\nboston = d.load_boston()\nprint(boston.DESCR)\n```\n\n内部数据的接口用：datasets.load_*?()\n\n# 外部数据\n\ndatasets模块也包含了API获取外部的数据。这些API以 fetch_*? 开头。\n\n```python\nhousing = datasets.fetch_california_housing()\n```\n\n# 造数据\n\n除了已有的数据，scikit-learn还提供了丰富的API来生成少量的数据。\n\n这些接口都以datasets.make_*?开头。\n\n```python\ndatasets.make_regression(1000,10,5,2,1.0)\n```\n","slug":"scikitleanr-preparing-data","published":1,"updated":"2016-11-22T06:25:01.333Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civt4av1o0004s4kb36nt76y1","content":"<blockquote>\n<p>种一棵树最好的时间，是十年前和现在</p>\n</blockquote>\n<p>终于决定踏入机器学习的世界。只为了那个梦想：养一个机器人在金融市场挖矿，然后去环游世界。</p>\n<p>选择scikit-learn，是因为python已经成为事实上的数据分析和挖掘的语言，是很多数据科学家的首选。而且scikit-learn还可以与Spark集成，感谢Databricks的工程师。</p>\n<p>参考：<a href=\"https://databricks.com/blog/2016/02/08/auto-scaling-scikit-learn-with-apache-spark.html\" target=\"_blank\" rel=\"external\">Auto-scaling scikit-learn with Apache Spark</a></p>\n<p>俗话说：兵马未动粮草先行。要学习scikit-learn，首先需要有数据。作为学习，Scikit-learn提供了三种方式获取数据。</p>\n<h1 id=\"内部自带的数据\"><a href=\"#内部自带的数据\" class=\"headerlink\" title=\"内部自带的数据\"></a>内部自带的数据</h1><p>scikit-learn包自带的数据在datasets模块当中。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</div><div class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</div></pre></td></tr></table></figure>\n<p>在IPython中，通过输入datasets.*?会列出datasets包含的所有API。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">boston = d.load_boston()</div><div class=\"line\">print(boston.DESCR)</div></pre></td></tr></table></figure>\n<p>内部数据的接口用：datasets.load_*?()</p>\n<h1 id=\"外部数据\"><a href=\"#外部数据\" class=\"headerlink\" title=\"外部数据\"></a>外部数据</h1><p>datasets模块也包含了API获取外部的数据。这些API以 fetch_*? 开头。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">housing = datasets.fetch_california_housing()</div></pre></td></tr></table></figure>\n<h1 id=\"造数据\"><a href=\"#造数据\" class=\"headerlink\" title=\"造数据\"></a>造数据</h1><p>除了已有的数据，scikit-learn还提供了丰富的API来生成少量的数据。</p>\n<p>这些接口都以datasets.make_*?开头。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">datasets.make_regression(<span class=\"number\">1000</span>,<span class=\"number\">10</span>,<span class=\"number\">5</span>,<span class=\"number\">2</span>,<span class=\"number\">1.0</span>)</div></pre></td></tr></table></figure>\n","excerpt":"","more":"<blockquote>\n<p>种一棵树最好的时间，是十年前和现在</p>\n</blockquote>\n<p>终于决定踏入机器学习的世界。只为了那个梦想：养一个机器人在金融市场挖矿，然后去环游世界。</p>\n<p>选择scikit-learn，是因为python已经成为事实上的数据分析和挖掘的语言，是很多数据科学家的首选。而且scikit-learn还可以与Spark集成，感谢Databricks的工程师。</p>\n<p>参考：<a href=\"https://databricks.com/blog/2016/02/08/auto-scaling-scikit-learn-with-apache-spark.html\">Auto-scaling scikit-learn with Apache Spark</a></p>\n<p>俗话说：兵马未动粮草先行。要学习scikit-learn，首先需要有数据。作为学习，Scikit-learn提供了三种方式获取数据。</p>\n<h1 id=\"内部自带的数据\"><a href=\"#内部自带的数据\" class=\"headerlink\" title=\"内部自带的数据\"></a>内部自带的数据</h1><p>scikit-learn包自带的数据在datasets模块当中。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</div><div class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</div></pre></td></tr></table></figure>\n<p>在IPython中，通过输入datasets.*?会列出datasets包含的所有API。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">boston = d.load_boston()</div><div class=\"line\">print(boston.DESCR)</div></pre></td></tr></table></figure>\n<p>内部数据的接口用：datasets.load_*?()</p>\n<h1 id=\"外部数据\"><a href=\"#外部数据\" class=\"headerlink\" title=\"外部数据\"></a>外部数据</h1><p>datasets模块也包含了API获取外部的数据。这些API以 fetch_*? 开头。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">housing = datasets.fetch_california_housing()</div></pre></td></tr></table></figure>\n<h1 id=\"造数据\"><a href=\"#造数据\" class=\"headerlink\" title=\"造数据\"></a>造数据</h1><p>除了已有的数据，scikit-learn还提供了丰富的API来生成少量的数据。</p>\n<p>这些接口都以datasets.make_*?开头。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">datasets.make_regression(<span class=\"number\">1000</span>,<span class=\"number\">10</span>,<span class=\"number\">5</span>,<span class=\"number\">2</span>,<span class=\"number\">1.0</span>)</div></pre></td></tr></table></figure>\n"},{"title":"Spark性能调优","date":"2016-11-20T02:44:15.000Z","_content":"\n# 前言\n\nSpark是一个优秀的弹性分布式计算系统，但是它不是一个“神奇”的分布式系统，你需要正确的使用它提供的API并且合理的分配资源。\n本文介绍的技巧主要是针对原生的RDD API。Spark SQL和Dataset在引擎层面提供了不同程度的优化，以后的文章再专门介绍。\n\n# 概念\n\n在Spark体系里，有两个层面的概念需要掌握。\n\n- 开发层面：RDD, Transformation, Action等\n- 执行层面：Job、Stage、Task、Executor、Shuffle、Partition\n\n那么在进行程序优化的时候，也要针对这两个层面进行优化。不仅要正确的编写Spark的程序，还要在执行程序的时候，正确的分配资源。\n\n# Spark如何运行你的程序\n\n一个典型的Spark应用，都有一个Driver和多个Executor。Driver是一个中心调度器，负责把Job分配给各个executor。executor分布\n在集群的各个机器上，负责执行任务。\n\n![Spark执行图](/images/spark-tuning-f1.png)\n\nRDD的tranformation不会触发程序的执行，只有Action才会。一个Action API对应一个Job的执行。\n\n一个Job分成很多个Stage，每个Stage被划分成很多个Task，每个Task运行的代码是一样的，只是他们操作在不同分区（partition）的数据上。这些Task会被分派\n到各个Executor上去执行，一个Executor可以同时执行多个Task，取决于Executor能分配的资源(CPU,内存).\n\n在一个Stage内部的所有Transformation操作都不会触发Shuffle。Stage之间会发生shuffle。（反过来想，如果两个stage之间没有shuffle，那么可以合成一个Stage ^-^)\n\n在了解了Spark的运行机制后，那么就可以针对其中的每个环节进行优化。\n\n# [优化1] 减少不必要的Shuffle\n\nShuffle的意思是洗牌。就像洗扑克牌一样，把数据重新排列分部。注意Shuffle很多时候是必可避免的，甚至有时候为了提高性能，需要先进行shuffle把数据重新分配到更多的分区以利用集群的计算资源。\n但是我们一定要努力减少**不必要**的Shuffle操作，因为Shuffle会把数据写到硬盘，然后供下一个stage读取。这会大大增加网络和IO的消耗。记住，在大数据的世界里，“计算”是比“数据”更便宜的资源。\n要尽量移动计算，而不是数据。\n\n而不必要的Shuffle的产生，往往和错误的使用API有关。\n\n## Shuffle是如何产生的\n\nRDD是Spark的核心。RDD是一种分布式的数据结构，但RDD提供很多API来操作数据。\n\n有一些API，例如filter(), map()， 对于一个分区的数据，可以直接进行操作。这类操作被称为Narrow Transformation (narrow我的理解就是没有夸partition之间的依赖)。\n而又另外的一些API，例如groupByKey(), reduceByKey()，这些操作需要把相同key的数据都先放到一个partition，以便于能被同一个task执行。这类操作被称为Wide Transformation。\n这时候就需要进行shuffle。\n\nHere are all RDD Transformation (v2.0)\n\n**Narrow Transformation:**\n- map\n- filter\n- flatMap\n- mapPartitions\n- mapPartitionsWithIndex\n- sample\n- union\n- intersection\n- distinct ??\n\n\n** Wide Transformation:**\n- groupByKey\n- reduceByKey\n- aggregateByKey\n- sortByKey\n- join (Not always)\n- cogroup\n- cartesian\n- repartition\n- repartitionAndSortWithPartitions\n- coalesce\n\n*例子*\n\n```scala\nsc.textFile(\"someFile.txt\").\n  map(mapFunc).\n  flatMap(flatMapFunc).\n  filter(filterFunc).\n  count()\n```\n\n这段代码里，有一个action：count()，因此会产生一个job。这个job只包含一个stage，所有的tranformation都没有操作涉及到shuffle。\n\n```scala\nval tokenized = sc.textFile(args(0)).flatMap(_.split(' '))\nval wordCounts = tokenized.map((_, 1)).reduceByKey(_ + _)\nval filtered = wordCounts.filter(_._2 >= 1000)\nval charCounts = filtered.flatMap(_._1.toCharArray).map((_, 1)).\n  reduceByKey(_ + _)\ncharCounts.collect()\n```\n\n这段代码有一个action：collect()。它有两个wide transformation: reduceByKey()， 这两个reduceByKey()操作把job划分为3个stage，第一个和第二个stage要做shuffle的操作。\n\n1. 第一个stage：textFile --> flatMap --> map --> reduceByKey\n2. 第二个stage: filter --> flatMap --> map --> reduceByKey\n3. 第三个stage: count\n\n## 正确的使用API\n\n条条大路通罗马，但不是每条道路都省时省心。在使用Spark的API进行数据运算时，往往有很多种做法，但不是每种做法都是高效的。\n\n总的原则：避免shuffle或者减少shuffle的数据量。\n\n1. 在使用reduce能使数据减少的情况下，使用reduceBykey()而不是groupByKey()\n\nrdd.groupByKey().mapValues(_.sum) 会将整个RDD先shuffle然后再对每个partition的数据进行相加\nrdd.reduceByKey(_ + _) 会将每个partition的数据先加在一起，然后再shuffle\n\n这样能显著减少shuffle的数据量。但是如果reduce的算子不是 _ + _， 而是某些让数据数量不变甚至增长的情况，则不适用。\n\n2. 如果目标RDD的类型是一个集合类型，尽量使用mutable的集合类型\n\n\n```\nrdd.map(kv => (kv._1, new Set[String]() + kv._2))\n    .reduceByKey(_ ++ _)\n```\n这种写法会为每一个map操作新建一个Set，非常损耗性能。\n\n```\nval zero = new collection.mutable.Set[String]()\nrdd.aggregateByKey(zero)(\n    (set, v) => set += v,\n    (set1, set2) => set1 ++= set2)\n```\n这种写法没有每次new一个Set的开销，更加高效。\n\n3. 当数据量很少时，使用Broadcast而不是建成一个RDD。\n\n通常做法是把一个集合变成一个哈希表，然后广播到各个executor，然后在做Map操作时，直接通过Key来引用对应的值。\n\n## Partition对shuffle的影响\n\nSpark总是竭尽所能减少shuffle的发生。例如：\n\n```\nrdd1 = someRdd.reduceByKey(...)\nrdd2 = someOtherRdd.reduceByKey(...)\nrdd3 = rdd1.join(rdd2)\n```\n\n如果没有优化，那么产生rdd1需要一次shuffle，产生rdd2需要一次shuffle，产生rdd3需要两次shuffle （rdd1和rdd2各自shuffle一次）\n\nrdd1和rdd2都使用reduceByKey()并且没有指定partitioner，那么他们使用的是默认的partitioner, 如果他们的partition数据也是一样的，\n同样的key在两个RDD中都只能位于各自的某个partition中，rdd3的每个partition的数据都来源于rdd1和rdd2的一个partition。因此总共shuffle了两次。\n\n但是如果rdd1和rdd2两个的partition数目不一样，或者数据一样，但是他们的partitioner不一样，那么就总共需要三次次shuffle。\n第一次: someRdd进行shuffle然后得到rdd1\n第二次: someOtherRDD进行shuffle然后得到rdd2\n第三次：将partition数目较少的RDD进行shuffle，使得和partition数据较多的RDD partition数目一样，然后再进行join。\n\n\n# 优化2：合理分配计算资源\n\n除了尽量避免shuffle的产生或者减少shuffle的数据量，还需要为每个executor分配正确的资源。Spark管理的资源主要有CPU和内存。\n对于网络和IO等资源，Spark并没有提供主动的管理。\n\n这里主要讲基于Yarn的资源分配。\n\n## CPU内核分配\n\nSpark可以给每个executor指定其最大可以使用的CPU核数。\n\n有三个地方可以指定：\n\n- spark-submit,spark-shell: --executor-cores\n- spark-defaults.conf: spark.executor.cores\n- SparkConf\n\n当Spark和Yarn结合时，Spark能申请的CPU资源还要受限于Yarn。\n\nyarn.nodemanager.resource.cpu-vcores 参数控制每个Yarn容器能使用的CPU数目。\n\n当Spark申请3个核时，实际上Spark是向Yarn申请了3个vcores.\n\n## 内存分配\n\n有三个地方可以指定：\n\n-  spark-submit,spark-shell: --executor-memory\n-  spark-defaults.conf: spark.executor.memory\n-  SparkConf\n\nSpark向Yarn申请内存时比申请CPU要复杂。\n\n- --executor-memory 控制的是executor的堆大小，但是每个executor还需要使用额外的内存空间来做缓存。\n- spark.yarn.executor.memoryOverhead 用于控制向Yarn申请的额外的内存。它的默认值等于：max(384, 0.07 * spark.executor.memory)\n- yarn.scheduler.minimum-allocation-mb 控制一个yarn容器最小分配的内存\n\n![Spark内存申请](/images/spark-tuning2-f1.png)\n\n## 分配原则\n\n1. Spark的application master也需要占用资源。在yarn-client模式下，默认占用1个CPU核和1G内存。在yarn-cluster模式下，application\nmaster就是driver，由于application master同时也可能跑executor，因此要通过 --driver-memory 和 --driver-cores来为driver预留\n足够的程序。\n2. 不应该为一个executor分配太多的内存，这样反而会引起垃圾回收的延时。一般一个executor分配的内存最大不超过64G\n3. 一个executor一般分配不超过5个CPU核心，太多的话可能会使得hadoop写入文件阻塞（希望后来没有这个问题 !)\n4. 尽量不要分配一个executor只有一个CPU内核，然后在一台机器上创建很多个executor。主要有两个坏处：\n    - broadcast是建立在executor上的，太多executor导致太多的广播变量\n    - 每个executor都会占用一个额外的内存开销\n5. 永远要预留一个CPU内核和一定的内存供操作系统使用\n\n## 实例\n\n假设一个集群有6台机器，每台机器有16核，64G内存，那么该如何分配资源呢？\n\n首先给yarn分配资源：\n\nyarn.nodemanager.resource.cpu-vcores 15\nyarn.nodemanager.resource.memory-mb  63G\n\n要为系统进程预留1个核和1G的内存。\n\n\n然后给spark的executor分配CPU和内存。一种最直接的分配方案：\n\n--num-executors=6  --executor-cores=15 --executor-memory=63G\n\n也就是每天机器创建一个executor，每个executor占用15个核心，63G内存。但这是一个不可行的方案。首先每个executor分配15个核心，会导致HDFS\n被阻塞，而且一个executor占用63G内存，加上额外的开销就超过63G了。\n\n一种优化的方案为：\n\n--num-executors=17  --executor-cores=5 --executor-memory=19\n\n- 每个executor占用5个核心。--executor-cores=5\n- 每个机器可以有 15 / 5 = 3 个executor, 6台机器一共可以创建18个executor，但是我们要除去application master， 因此共有18-1=17个executor\n- 每天机器上的3个executor，每个executor可以分配到 63 / 3 = 21 G内存，但是 21G应该是包含了额外的开销的，假设额外开销为 0.07 * X\n  0.07 * X + X = 21, X = 19.6, 向下舍去，为19G\n\n这样的分配不仅可以充分利用资源，而且一般不会出现内存溢出的情况。\n\n\n# 优化三：使用更高效的数据存储\n\n例如使用parquet替代CSV，JSON，使用KryoSerializer替代默认的Java Serializer。这里不做重点介绍。\n\n# 优化四：增加并行度\n\n一般来说，在一个Stage里，task的数目和父亲RDD的partition数据是一样的 ，产生的子RDD的partition数目也是一样的。\n\n但是有些操作，可以改变子RDD的partition数目：\n\n- coalesce可以将父亲RDD的分区数目压缩\n- union操作产生的RDD分区数目是两个父亲RDD分区的和。\n- catesian产生的RDD分区数据是两个父亲RDD分区的乘积。\n\n分区的数据，决定了Job并行执行的程度。如果有100机器，但是数据只有2个分区，那么一次就只有2个task在执行，其它机器都在空转。\n\n分区太少，会使得单个task要执行的数据过多，占用的时间和空间也较大。那么到底分多少个分区合适呢？\n\n第一种办法就是不断的尝试逼近：找到父亲RDD的分区数目，然后不断乘以1.5，知道发现性能无法获得提升为止。但是这种办法在显示中不太可行，\n因为你不太可能一次次的去跑同样的job。\n\n另外一种尝试就是，根据系统的CPU，内存结合程序的特点来大概计算，但是很难量化。\n\n总的原则就是：多些分区要比少分区要好，因为在spark里创建task是很便宜的。\n\n\n\n# 参考资料\n\n- http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-1/\n- http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-2/\n\n\n\n\n\n","source":"_posts/spark-performance-tuning.md","raw":"---\ntitle: Spark性能调优\ndate: 2016-11-20 10:44:15\ntags: Spark\n---\n\n# 前言\n\nSpark是一个优秀的弹性分布式计算系统，但是它不是一个“神奇”的分布式系统，你需要正确的使用它提供的API并且合理的分配资源。\n本文介绍的技巧主要是针对原生的RDD API。Spark SQL和Dataset在引擎层面提供了不同程度的优化，以后的文章再专门介绍。\n\n# 概念\n\n在Spark体系里，有两个层面的概念需要掌握。\n\n- 开发层面：RDD, Transformation, Action等\n- 执行层面：Job、Stage、Task、Executor、Shuffle、Partition\n\n那么在进行程序优化的时候，也要针对这两个层面进行优化。不仅要正确的编写Spark的程序，还要在执行程序的时候，正确的分配资源。\n\n# Spark如何运行你的程序\n\n一个典型的Spark应用，都有一个Driver和多个Executor。Driver是一个中心调度器，负责把Job分配给各个executor。executor分布\n在集群的各个机器上，负责执行任务。\n\n![Spark执行图](/images/spark-tuning-f1.png)\n\nRDD的tranformation不会触发程序的执行，只有Action才会。一个Action API对应一个Job的执行。\n\n一个Job分成很多个Stage，每个Stage被划分成很多个Task，每个Task运行的代码是一样的，只是他们操作在不同分区（partition）的数据上。这些Task会被分派\n到各个Executor上去执行，一个Executor可以同时执行多个Task，取决于Executor能分配的资源(CPU,内存).\n\n在一个Stage内部的所有Transformation操作都不会触发Shuffle。Stage之间会发生shuffle。（反过来想，如果两个stage之间没有shuffle，那么可以合成一个Stage ^-^)\n\n在了解了Spark的运行机制后，那么就可以针对其中的每个环节进行优化。\n\n# [优化1] 减少不必要的Shuffle\n\nShuffle的意思是洗牌。就像洗扑克牌一样，把数据重新排列分部。注意Shuffle很多时候是必可避免的，甚至有时候为了提高性能，需要先进行shuffle把数据重新分配到更多的分区以利用集群的计算资源。\n但是我们一定要努力减少**不必要**的Shuffle操作，因为Shuffle会把数据写到硬盘，然后供下一个stage读取。这会大大增加网络和IO的消耗。记住，在大数据的世界里，“计算”是比“数据”更便宜的资源。\n要尽量移动计算，而不是数据。\n\n而不必要的Shuffle的产生，往往和错误的使用API有关。\n\n## Shuffle是如何产生的\n\nRDD是Spark的核心。RDD是一种分布式的数据结构，但RDD提供很多API来操作数据。\n\n有一些API，例如filter(), map()， 对于一个分区的数据，可以直接进行操作。这类操作被称为Narrow Transformation (narrow我的理解就是没有夸partition之间的依赖)。\n而又另外的一些API，例如groupByKey(), reduceByKey()，这些操作需要把相同key的数据都先放到一个partition，以便于能被同一个task执行。这类操作被称为Wide Transformation。\n这时候就需要进行shuffle。\n\nHere are all RDD Transformation (v2.0)\n\n**Narrow Transformation:**\n- map\n- filter\n- flatMap\n- mapPartitions\n- mapPartitionsWithIndex\n- sample\n- union\n- intersection\n- distinct ??\n\n\n** Wide Transformation:**\n- groupByKey\n- reduceByKey\n- aggregateByKey\n- sortByKey\n- join (Not always)\n- cogroup\n- cartesian\n- repartition\n- repartitionAndSortWithPartitions\n- coalesce\n\n*例子*\n\n```scala\nsc.textFile(\"someFile.txt\").\n  map(mapFunc).\n  flatMap(flatMapFunc).\n  filter(filterFunc).\n  count()\n```\n\n这段代码里，有一个action：count()，因此会产生一个job。这个job只包含一个stage，所有的tranformation都没有操作涉及到shuffle。\n\n```scala\nval tokenized = sc.textFile(args(0)).flatMap(_.split(' '))\nval wordCounts = tokenized.map((_, 1)).reduceByKey(_ + _)\nval filtered = wordCounts.filter(_._2 >= 1000)\nval charCounts = filtered.flatMap(_._1.toCharArray).map((_, 1)).\n  reduceByKey(_ + _)\ncharCounts.collect()\n```\n\n这段代码有一个action：collect()。它有两个wide transformation: reduceByKey()， 这两个reduceByKey()操作把job划分为3个stage，第一个和第二个stage要做shuffle的操作。\n\n1. 第一个stage：textFile --> flatMap --> map --> reduceByKey\n2. 第二个stage: filter --> flatMap --> map --> reduceByKey\n3. 第三个stage: count\n\n## 正确的使用API\n\n条条大路通罗马，但不是每条道路都省时省心。在使用Spark的API进行数据运算时，往往有很多种做法，但不是每种做法都是高效的。\n\n总的原则：避免shuffle或者减少shuffle的数据量。\n\n1. 在使用reduce能使数据减少的情况下，使用reduceBykey()而不是groupByKey()\n\nrdd.groupByKey().mapValues(_.sum) 会将整个RDD先shuffle然后再对每个partition的数据进行相加\nrdd.reduceByKey(_ + _) 会将每个partition的数据先加在一起，然后再shuffle\n\n这样能显著减少shuffle的数据量。但是如果reduce的算子不是 _ + _， 而是某些让数据数量不变甚至增长的情况，则不适用。\n\n2. 如果目标RDD的类型是一个集合类型，尽量使用mutable的集合类型\n\n\n```\nrdd.map(kv => (kv._1, new Set[String]() + kv._2))\n    .reduceByKey(_ ++ _)\n```\n这种写法会为每一个map操作新建一个Set，非常损耗性能。\n\n```\nval zero = new collection.mutable.Set[String]()\nrdd.aggregateByKey(zero)(\n    (set, v) => set += v,\n    (set1, set2) => set1 ++= set2)\n```\n这种写法没有每次new一个Set的开销，更加高效。\n\n3. 当数据量很少时，使用Broadcast而不是建成一个RDD。\n\n通常做法是把一个集合变成一个哈希表，然后广播到各个executor，然后在做Map操作时，直接通过Key来引用对应的值。\n\n## Partition对shuffle的影响\n\nSpark总是竭尽所能减少shuffle的发生。例如：\n\n```\nrdd1 = someRdd.reduceByKey(...)\nrdd2 = someOtherRdd.reduceByKey(...)\nrdd3 = rdd1.join(rdd2)\n```\n\n如果没有优化，那么产生rdd1需要一次shuffle，产生rdd2需要一次shuffle，产生rdd3需要两次shuffle （rdd1和rdd2各自shuffle一次）\n\nrdd1和rdd2都使用reduceByKey()并且没有指定partitioner，那么他们使用的是默认的partitioner, 如果他们的partition数据也是一样的，\n同样的key在两个RDD中都只能位于各自的某个partition中，rdd3的每个partition的数据都来源于rdd1和rdd2的一个partition。因此总共shuffle了两次。\n\n但是如果rdd1和rdd2两个的partition数目不一样，或者数据一样，但是他们的partitioner不一样，那么就总共需要三次次shuffle。\n第一次: someRdd进行shuffle然后得到rdd1\n第二次: someOtherRDD进行shuffle然后得到rdd2\n第三次：将partition数目较少的RDD进行shuffle，使得和partition数据较多的RDD partition数目一样，然后再进行join。\n\n\n# 优化2：合理分配计算资源\n\n除了尽量避免shuffle的产生或者减少shuffle的数据量，还需要为每个executor分配正确的资源。Spark管理的资源主要有CPU和内存。\n对于网络和IO等资源，Spark并没有提供主动的管理。\n\n这里主要讲基于Yarn的资源分配。\n\n## CPU内核分配\n\nSpark可以给每个executor指定其最大可以使用的CPU核数。\n\n有三个地方可以指定：\n\n- spark-submit,spark-shell: --executor-cores\n- spark-defaults.conf: spark.executor.cores\n- SparkConf\n\n当Spark和Yarn结合时，Spark能申请的CPU资源还要受限于Yarn。\n\nyarn.nodemanager.resource.cpu-vcores 参数控制每个Yarn容器能使用的CPU数目。\n\n当Spark申请3个核时，实际上Spark是向Yarn申请了3个vcores.\n\n## 内存分配\n\n有三个地方可以指定：\n\n-  spark-submit,spark-shell: --executor-memory\n-  spark-defaults.conf: spark.executor.memory\n-  SparkConf\n\nSpark向Yarn申请内存时比申请CPU要复杂。\n\n- --executor-memory 控制的是executor的堆大小，但是每个executor还需要使用额外的内存空间来做缓存。\n- spark.yarn.executor.memoryOverhead 用于控制向Yarn申请的额外的内存。它的默认值等于：max(384, 0.07 * spark.executor.memory)\n- yarn.scheduler.minimum-allocation-mb 控制一个yarn容器最小分配的内存\n\n![Spark内存申请](/images/spark-tuning2-f1.png)\n\n## 分配原则\n\n1. Spark的application master也需要占用资源。在yarn-client模式下，默认占用1个CPU核和1G内存。在yarn-cluster模式下，application\nmaster就是driver，由于application master同时也可能跑executor，因此要通过 --driver-memory 和 --driver-cores来为driver预留\n足够的程序。\n2. 不应该为一个executor分配太多的内存，这样反而会引起垃圾回收的延时。一般一个executor分配的内存最大不超过64G\n3. 一个executor一般分配不超过5个CPU核心，太多的话可能会使得hadoop写入文件阻塞（希望后来没有这个问题 !)\n4. 尽量不要分配一个executor只有一个CPU内核，然后在一台机器上创建很多个executor。主要有两个坏处：\n    - broadcast是建立在executor上的，太多executor导致太多的广播变量\n    - 每个executor都会占用一个额外的内存开销\n5. 永远要预留一个CPU内核和一定的内存供操作系统使用\n\n## 实例\n\n假设一个集群有6台机器，每台机器有16核，64G内存，那么该如何分配资源呢？\n\n首先给yarn分配资源：\n\nyarn.nodemanager.resource.cpu-vcores 15\nyarn.nodemanager.resource.memory-mb  63G\n\n要为系统进程预留1个核和1G的内存。\n\n\n然后给spark的executor分配CPU和内存。一种最直接的分配方案：\n\n--num-executors=6  --executor-cores=15 --executor-memory=63G\n\n也就是每天机器创建一个executor，每个executor占用15个核心，63G内存。但这是一个不可行的方案。首先每个executor分配15个核心，会导致HDFS\n被阻塞，而且一个executor占用63G内存，加上额外的开销就超过63G了。\n\n一种优化的方案为：\n\n--num-executors=17  --executor-cores=5 --executor-memory=19\n\n- 每个executor占用5个核心。--executor-cores=5\n- 每个机器可以有 15 / 5 = 3 个executor, 6台机器一共可以创建18个executor，但是我们要除去application master， 因此共有18-1=17个executor\n- 每天机器上的3个executor，每个executor可以分配到 63 / 3 = 21 G内存，但是 21G应该是包含了额外的开销的，假设额外开销为 0.07 * X\n  0.07 * X + X = 21, X = 19.6, 向下舍去，为19G\n\n这样的分配不仅可以充分利用资源，而且一般不会出现内存溢出的情况。\n\n\n# 优化三：使用更高效的数据存储\n\n例如使用parquet替代CSV，JSON，使用KryoSerializer替代默认的Java Serializer。这里不做重点介绍。\n\n# 优化四：增加并行度\n\n一般来说，在一个Stage里，task的数目和父亲RDD的partition数据是一样的 ，产生的子RDD的partition数目也是一样的。\n\n但是有些操作，可以改变子RDD的partition数目：\n\n- coalesce可以将父亲RDD的分区数目压缩\n- union操作产生的RDD分区数目是两个父亲RDD分区的和。\n- catesian产生的RDD分区数据是两个父亲RDD分区的乘积。\n\n分区的数据，决定了Job并行执行的程度。如果有100机器，但是数据只有2个分区，那么一次就只有2个task在执行，其它机器都在空转。\n\n分区太少，会使得单个task要执行的数据过多，占用的时间和空间也较大。那么到底分多少个分区合适呢？\n\n第一种办法就是不断的尝试逼近：找到父亲RDD的分区数目，然后不断乘以1.5，知道发现性能无法获得提升为止。但是这种办法在显示中不太可行，\n因为你不太可能一次次的去跑同样的job。\n\n另外一种尝试就是，根据系统的CPU，内存结合程序的特点来大概计算，但是很难量化。\n\n总的原则就是：多些分区要比少分区要好，因为在spark里创建task是很便宜的。\n\n\n\n# 参考资料\n\n- http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-1/\n- http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-2/\n\n\n\n\n\n","slug":"spark-performance-tuning","published":1,"updated":"2016-11-21T02:56:28.322Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civt4av1o0005s4kbe52zd5fa","content":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>Spark是一个优秀的弹性分布式计算系统，但是它不是一个“神奇”的分布式系统，你需要正确的使用它提供的API并且合理的分配资源。<br>本文介绍的技巧主要是针对原生的RDD API。Spark SQL和Dataset在引擎层面提供了不同程度的优化，以后的文章再专门介绍。</p>\n<h1 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h1><p>在Spark体系里，有两个层面的概念需要掌握。</p>\n<ul>\n<li>开发层面：RDD, Transformation, Action等</li>\n<li>执行层面：Job、Stage、Task、Executor、Shuffle、Partition</li>\n</ul>\n<p>那么在进行程序优化的时候，也要针对这两个层面进行优化。不仅要正确的编写Spark的程序，还要在执行程序的时候，正确的分配资源。</p>\n<h1 id=\"Spark如何运行你的程序\"><a href=\"#Spark如何运行你的程序\" class=\"headerlink\" title=\"Spark如何运行你的程序\"></a>Spark如何运行你的程序</h1><p>一个典型的Spark应用，都有一个Driver和多个Executor。Driver是一个中心调度器，负责把Job分配给各个executor。executor分布<br>在集群的各个机器上，负责执行任务。</p>\n<p><img src=\"/images/spark-tuning-f1.png\" alt=\"Spark执行图\"></p>\n<p>RDD的tranformation不会触发程序的执行，只有Action才会。一个Action API对应一个Job的执行。</p>\n<p>一个Job分成很多个Stage，每个Stage被划分成很多个Task，每个Task运行的代码是一样的，只是他们操作在不同分区（partition）的数据上。这些Task会被分派<br>到各个Executor上去执行，一个Executor可以同时执行多个Task，取决于Executor能分配的资源(CPU,内存).</p>\n<p>在一个Stage内部的所有Transformation操作都不会触发Shuffle。Stage之间会发生shuffle。（反过来想，如果两个stage之间没有shuffle，那么可以合成一个Stage ^-^)</p>\n<p>在了解了Spark的运行机制后，那么就可以针对其中的每个环节进行优化。</p>\n<h1 id=\"优化1-减少不必要的Shuffle\"><a href=\"#优化1-减少不必要的Shuffle\" class=\"headerlink\" title=\"[优化1] 减少不必要的Shuffle\"></a>[优化1] 减少不必要的Shuffle</h1><p>Shuffle的意思是洗牌。就像洗扑克牌一样，把数据重新排列分部。注意Shuffle很多时候是必可避免的，甚至有时候为了提高性能，需要先进行shuffle把数据重新分配到更多的分区以利用集群的计算资源。<br>但是我们一定要努力减少<strong>不必要</strong>的Shuffle操作，因为Shuffle会把数据写到硬盘，然后供下一个stage读取。这会大大增加网络和IO的消耗。记住，在大数据的世界里，“计算”是比“数据”更便宜的资源。<br>要尽量移动计算，而不是数据。</p>\n<p>而不必要的Shuffle的产生，往往和错误的使用API有关。</p>\n<h2 id=\"Shuffle是如何产生的\"><a href=\"#Shuffle是如何产生的\" class=\"headerlink\" title=\"Shuffle是如何产生的\"></a>Shuffle是如何产生的</h2><p>RDD是Spark的核心。RDD是一种分布式的数据结构，但RDD提供很多API来操作数据。</p>\n<p>有一些API，例如filter(), map()， 对于一个分区的数据，可以直接进行操作。这类操作被称为Narrow Transformation (narrow我的理解就是没有夸partition之间的依赖)。<br>而又另外的一些API，例如groupByKey(), reduceByKey()，这些操作需要把相同key的数据都先放到一个partition，以便于能被同一个task执行。这类操作被称为Wide Transformation。<br>这时候就需要进行shuffle。</p>\n<p>Here are all RDD Transformation (v2.0)</p>\n<p><strong>Narrow Transformation:</strong></p>\n<ul>\n<li>map</li>\n<li>filter</li>\n<li>flatMap</li>\n<li>mapPartitions</li>\n<li>mapPartitionsWithIndex</li>\n<li>sample</li>\n<li>union</li>\n<li>intersection</li>\n<li>distinct ??</li>\n</ul>\n<p><strong> Wide Transformation:</strong></p>\n<ul>\n<li>groupByKey</li>\n<li>reduceByKey</li>\n<li>aggregateByKey</li>\n<li>sortByKey</li>\n<li>join (Not always)</li>\n<li>cogroup</li>\n<li>cartesian</li>\n<li>repartition</li>\n<li>repartitionAndSortWithPartitions</li>\n<li>coalesce</li>\n</ul>\n<p><em>例子</em></p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">sc.textFile(<span class=\"string\">\"someFile.txt\"</span>).</div><div class=\"line\">  map(mapFunc).</div><div class=\"line\">  flatMap(flatMapFunc).</div><div class=\"line\">  filter(filterFunc).</div><div class=\"line\">  count()</div></pre></td></tr></table></figure>\n<p>这段代码里，有一个action：count()，因此会产生一个job。这个job只包含一个stage，所有的tranformation都没有操作涉及到shuffle。</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">val</span> tokenized = sc.textFile(args(<span class=\"number\">0</span>)).flatMap(_.split(' '))</div><div class=\"line\"><span class=\"keyword\">val</span> wordCounts = tokenized.map((_, <span class=\"number\">1</span>)).reduceByKey(_ + _)</div><div class=\"line\"><span class=\"keyword\">val</span> filtered = wordCounts.filter(_._2 &gt;= <span class=\"number\">1000</span>)</div><div class=\"line\"><span class=\"keyword\">val</span> charCounts = filtered.flatMap(_._1.toCharArray).map((_, <span class=\"number\">1</span>)).</div><div class=\"line\">  reduceByKey(_ + _)</div><div class=\"line\">charCounts.collect()</div></pre></td></tr></table></figure>\n<p>这段代码有一个action：collect()。它有两个wide transformation: reduceByKey()， 这两个reduceByKey()操作把job划分为3个stage，第一个和第二个stage要做shuffle的操作。</p>\n<ol>\n<li>第一个stage：textFile –&gt; flatMap –&gt; map –&gt; reduceByKey</li>\n<li>第二个stage: filter –&gt; flatMap –&gt; map –&gt; reduceByKey</li>\n<li>第三个stage: count</li>\n</ol>\n<h2 id=\"正确的使用API\"><a href=\"#正确的使用API\" class=\"headerlink\" title=\"正确的使用API\"></a>正确的使用API</h2><p>条条大路通罗马，但不是每条道路都省时省心。在使用Spark的API进行数据运算时，往往有很多种做法，但不是每种做法都是高效的。</p>\n<p>总的原则：避免shuffle或者减少shuffle的数据量。</p>\n<ol>\n<li>在使用reduce能使数据减少的情况下，使用reduceBykey()而不是groupByKey()</li>\n</ol>\n<p>rdd.groupByKey().mapValues(<em>.sum) 会将整个RDD先shuffle然后再对每个partition的数据进行相加<br>rdd.reduceByKey(</em> + _) 会将每个partition的数据先加在一起，然后再shuffle</p>\n<p>这样能显著减少shuffle的数据量。但是如果reduce的算子不是 <em> + </em>， 而是某些让数据数量不变甚至增长的情况，则不适用。</p>\n<ol>\n<li>如果目标RDD的类型是一个集合类型，尽量使用mutable的集合类型</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">rdd.map(kv =&gt; (kv._1, new Set[String]() + kv._2))</div><div class=\"line\">    .reduceByKey(_ ++ _)</div></pre></td></tr></table></figure>\n<p>这种写法会为每一个map操作新建一个Set，非常损耗性能。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">val zero = new collection.mutable.Set[String]()</div><div class=\"line\">rdd.aggregateByKey(zero)(</div><div class=\"line\">    (set, v) =&gt; set += v,</div><div class=\"line\">    (set1, set2) =&gt; set1 ++= set2)</div></pre></td></tr></table></figure>\n<p>这种写法没有每次new一个Set的开销，更加高效。</p>\n<ol>\n<li>当数据量很少时，使用Broadcast而不是建成一个RDD。</li>\n</ol>\n<p>通常做法是把一个集合变成一个哈希表，然后广播到各个executor，然后在做Map操作时，直接通过Key来引用对应的值。</p>\n<h2 id=\"Partition对shuffle的影响\"><a href=\"#Partition对shuffle的影响\" class=\"headerlink\" title=\"Partition对shuffle的影响\"></a>Partition对shuffle的影响</h2><p>Spark总是竭尽所能减少shuffle的发生。例如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">rdd1 = someRdd.reduceByKey(...)</div><div class=\"line\">rdd2 = someOtherRdd.reduceByKey(...)</div><div class=\"line\">rdd3 = rdd1.join(rdd2)</div></pre></td></tr></table></figure>\n<p>如果没有优化，那么产生rdd1需要一次shuffle，产生rdd2需要一次shuffle，产生rdd3需要两次shuffle （rdd1和rdd2各自shuffle一次）</p>\n<p>rdd1和rdd2都使用reduceByKey()并且没有指定partitioner，那么他们使用的是默认的partitioner, 如果他们的partition数据也是一样的，<br>同样的key在两个RDD中都只能位于各自的某个partition中，rdd3的每个partition的数据都来源于rdd1和rdd2的一个partition。因此总共shuffle了两次。</p>\n<p>但是如果rdd1和rdd2两个的partition数目不一样，或者数据一样，但是他们的partitioner不一样，那么就总共需要三次次shuffle。<br>第一次: someRdd进行shuffle然后得到rdd1<br>第二次: someOtherRDD进行shuffle然后得到rdd2<br>第三次：将partition数目较少的RDD进行shuffle，使得和partition数据较多的RDD partition数目一样，然后再进行join。</p>\n<h1 id=\"优化2：合理分配计算资源\"><a href=\"#优化2：合理分配计算资源\" class=\"headerlink\" title=\"优化2：合理分配计算资源\"></a>优化2：合理分配计算资源</h1><p>除了尽量避免shuffle的产生或者减少shuffle的数据量，还需要为每个executor分配正确的资源。Spark管理的资源主要有CPU和内存。<br>对于网络和IO等资源，Spark并没有提供主动的管理。</p>\n<p>这里主要讲基于Yarn的资源分配。</p>\n<h2 id=\"CPU内核分配\"><a href=\"#CPU内核分配\" class=\"headerlink\" title=\"CPU内核分配\"></a>CPU内核分配</h2><p>Spark可以给每个executor指定其最大可以使用的CPU核数。</p>\n<p>有三个地方可以指定：</p>\n<ul>\n<li>spark-submit,spark-shell: –executor-cores</li>\n<li>spark-defaults.conf: spark.executor.cores</li>\n<li>SparkConf</li>\n</ul>\n<p>当Spark和Yarn结合时，Spark能申请的CPU资源还要受限于Yarn。</p>\n<p>yarn.nodemanager.resource.cpu-vcores 参数控制每个Yarn容器能使用的CPU数目。</p>\n<p>当Spark申请3个核时，实际上Spark是向Yarn申请了3个vcores.</p>\n<h2 id=\"内存分配\"><a href=\"#内存分配\" class=\"headerlink\" title=\"内存分配\"></a>内存分配</h2><p>有三个地方可以指定：</p>\n<ul>\n<li>spark-submit,spark-shell: –executor-memory</li>\n<li>spark-defaults.conf: spark.executor.memory</li>\n<li>SparkConf</li>\n</ul>\n<p>Spark向Yarn申请内存时比申请CPU要复杂。</p>\n<ul>\n<li>–executor-memory 控制的是executor的堆大小，但是每个executor还需要使用额外的内存空间来做缓存。</li>\n<li>spark.yarn.executor.memoryOverhead 用于控制向Yarn申请的额外的内存。它的默认值等于：max(384, 0.07 * spark.executor.memory)</li>\n<li>yarn.scheduler.minimum-allocation-mb 控制一个yarn容器最小分配的内存</li>\n</ul>\n<p><img src=\"/images/spark-tuning2-f1.png\" alt=\"Spark内存申请\"></p>\n<h2 id=\"分配原则\"><a href=\"#分配原则\" class=\"headerlink\" title=\"分配原则\"></a>分配原则</h2><ol>\n<li>Spark的application master也需要占用资源。在yarn-client模式下，默认占用1个CPU核和1G内存。在yarn-cluster模式下，application<br>master就是driver，由于application master同时也可能跑executor，因此要通过 –driver-memory 和 –driver-cores来为driver预留<br>足够的程序。</li>\n<li>不应该为一个executor分配太多的内存，这样反而会引起垃圾回收的延时。一般一个executor分配的内存最大不超过64G</li>\n<li>一个executor一般分配不超过5个CPU核心，太多的话可能会使得hadoop写入文件阻塞（希望后来没有这个问题 !)</li>\n<li>尽量不要分配一个executor只有一个CPU内核，然后在一台机器上创建很多个executor。主要有两个坏处：<ul>\n<li>broadcast是建立在executor上的，太多executor导致太多的广播变量</li>\n<li>每个executor都会占用一个额外的内存开销</li>\n</ul>\n</li>\n<li>永远要预留一个CPU内核和一定的内存供操作系统使用</li>\n</ol>\n<h2 id=\"实例\"><a href=\"#实例\" class=\"headerlink\" title=\"实例\"></a>实例</h2><p>假设一个集群有6台机器，每台机器有16核，64G内存，那么该如何分配资源呢？</p>\n<p>首先给yarn分配资源：</p>\n<p>yarn.nodemanager.resource.cpu-vcores 15<br>yarn.nodemanager.resource.memory-mb  63G</p>\n<p>要为系统进程预留1个核和1G的内存。</p>\n<p>然后给spark的executor分配CPU和内存。一种最直接的分配方案：</p>\n<p>–num-executors=6  –executor-cores=15 –executor-memory=63G</p>\n<p>也就是每天机器创建一个executor，每个executor占用15个核心，63G内存。但这是一个不可行的方案。首先每个executor分配15个核心，会导致HDFS<br>被阻塞，而且一个executor占用63G内存，加上额外的开销就超过63G了。</p>\n<p>一种优化的方案为：</p>\n<p>–num-executors=17  –executor-cores=5 –executor-memory=19</p>\n<ul>\n<li>每个executor占用5个核心。–executor-cores=5</li>\n<li>每个机器可以有 15 / 5 = 3 个executor, 6台机器一共可以创建18个executor，但是我们要除去application master， 因此共有18-1=17个executor</li>\n<li>每天机器上的3个executor，每个executor可以分配到 63 / 3 = 21 G内存，但是 21G应该是包含了额外的开销的，假设额外开销为 0.07 <em> X<br>0.07 </em> X + X = 21, X = 19.6, 向下舍去，为19G</li>\n</ul>\n<p>这样的分配不仅可以充分利用资源，而且一般不会出现内存溢出的情况。</p>\n<h1 id=\"优化三：使用更高效的数据存储\"><a href=\"#优化三：使用更高效的数据存储\" class=\"headerlink\" title=\"优化三：使用更高效的数据存储\"></a>优化三：使用更高效的数据存储</h1><p>例如使用parquet替代CSV，JSON，使用KryoSerializer替代默认的Java Serializer。这里不做重点介绍。</p>\n<h1 id=\"优化四：增加并行度\"><a href=\"#优化四：增加并行度\" class=\"headerlink\" title=\"优化四：增加并行度\"></a>优化四：增加并行度</h1><p>一般来说，在一个Stage里，task的数目和父亲RDD的partition数据是一样的 ，产生的子RDD的partition数目也是一样的。</p>\n<p>但是有些操作，可以改变子RDD的partition数目：</p>\n<ul>\n<li>coalesce可以将父亲RDD的分区数目压缩</li>\n<li>union操作产生的RDD分区数目是两个父亲RDD分区的和。</li>\n<li>catesian产生的RDD分区数据是两个父亲RDD分区的乘积。</li>\n</ul>\n<p>分区的数据，决定了Job并行执行的程度。如果有100机器，但是数据只有2个分区，那么一次就只有2个task在执行，其它机器都在空转。</p>\n<p>分区太少，会使得单个task要执行的数据过多，占用的时间和空间也较大。那么到底分多少个分区合适呢？</p>\n<p>第一种办法就是不断的尝试逼近：找到父亲RDD的分区数目，然后不断乘以1.5，知道发现性能无法获得提升为止。但是这种办法在显示中不太可行，<br>因为你不太可能一次次的去跑同样的job。</p>\n<p>另外一种尝试就是，根据系统的CPU，内存结合程序的特点来大概计算，但是很难量化。</p>\n<p>总的原则就是：多些分区要比少分区要好，因为在spark里创建task是很便宜的。</p>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li><a href=\"http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-1/\" target=\"_blank\" rel=\"external\">http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-1/</a></li>\n<li><a href=\"http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-2/\" target=\"_blank\" rel=\"external\">http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-2/</a></li>\n</ul>\n","excerpt":"","more":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>Spark是一个优秀的弹性分布式计算系统，但是它不是一个“神奇”的分布式系统，你需要正确的使用它提供的API并且合理的分配资源。<br>本文介绍的技巧主要是针对原生的RDD API。Spark SQL和Dataset在引擎层面提供了不同程度的优化，以后的文章再专门介绍。</p>\n<h1 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h1><p>在Spark体系里，有两个层面的概念需要掌握。</p>\n<ul>\n<li>开发层面：RDD, Transformation, Action等</li>\n<li>执行层面：Job、Stage、Task、Executor、Shuffle、Partition</li>\n</ul>\n<p>那么在进行程序优化的时候，也要针对这两个层面进行优化。不仅要正确的编写Spark的程序，还要在执行程序的时候，正确的分配资源。</p>\n<h1 id=\"Spark如何运行你的程序\"><a href=\"#Spark如何运行你的程序\" class=\"headerlink\" title=\"Spark如何运行你的程序\"></a>Spark如何运行你的程序</h1><p>一个典型的Spark应用，都有一个Driver和多个Executor。Driver是一个中心调度器，负责把Job分配给各个executor。executor分布<br>在集群的各个机器上，负责执行任务。</p>\n<p><img src=\"/images/spark-tuning-f1.png\" alt=\"Spark执行图\"></p>\n<p>RDD的tranformation不会触发程序的执行，只有Action才会。一个Action API对应一个Job的执行。</p>\n<p>一个Job分成很多个Stage，每个Stage被划分成很多个Task，每个Task运行的代码是一样的，只是他们操作在不同分区（partition）的数据上。这些Task会被分派<br>到各个Executor上去执行，一个Executor可以同时执行多个Task，取决于Executor能分配的资源(CPU,内存).</p>\n<p>在一个Stage内部的所有Transformation操作都不会触发Shuffle。Stage之间会发生shuffle。（反过来想，如果两个stage之间没有shuffle，那么可以合成一个Stage ^-^)</p>\n<p>在了解了Spark的运行机制后，那么就可以针对其中的每个环节进行优化。</p>\n<h1 id=\"优化1-减少不必要的Shuffle\"><a href=\"#优化1-减少不必要的Shuffle\" class=\"headerlink\" title=\"[优化1] 减少不必要的Shuffle\"></a>[优化1] 减少不必要的Shuffle</h1><p>Shuffle的意思是洗牌。就像洗扑克牌一样，把数据重新排列分部。注意Shuffle很多时候是必可避免的，甚至有时候为了提高性能，需要先进行shuffle把数据重新分配到更多的分区以利用集群的计算资源。<br>但是我们一定要努力减少<strong>不必要</strong>的Shuffle操作，因为Shuffle会把数据写到硬盘，然后供下一个stage读取。这会大大增加网络和IO的消耗。记住，在大数据的世界里，“计算”是比“数据”更便宜的资源。<br>要尽量移动计算，而不是数据。</p>\n<p>而不必要的Shuffle的产生，往往和错误的使用API有关。</p>\n<h2 id=\"Shuffle是如何产生的\"><a href=\"#Shuffle是如何产生的\" class=\"headerlink\" title=\"Shuffle是如何产生的\"></a>Shuffle是如何产生的</h2><p>RDD是Spark的核心。RDD是一种分布式的数据结构，但RDD提供很多API来操作数据。</p>\n<p>有一些API，例如filter(), map()， 对于一个分区的数据，可以直接进行操作。这类操作被称为Narrow Transformation (narrow我的理解就是没有夸partition之间的依赖)。<br>而又另外的一些API，例如groupByKey(), reduceByKey()，这些操作需要把相同key的数据都先放到一个partition，以便于能被同一个task执行。这类操作被称为Wide Transformation。<br>这时候就需要进行shuffle。</p>\n<p>Here are all RDD Transformation (v2.0)</p>\n<p><strong>Narrow Transformation:</strong></p>\n<ul>\n<li>map</li>\n<li>filter</li>\n<li>flatMap</li>\n<li>mapPartitions</li>\n<li>mapPartitionsWithIndex</li>\n<li>sample</li>\n<li>union</li>\n<li>intersection</li>\n<li>distinct ??</li>\n</ul>\n<p><strong> Wide Transformation:</strong></p>\n<ul>\n<li>groupByKey</li>\n<li>reduceByKey</li>\n<li>aggregateByKey</li>\n<li>sortByKey</li>\n<li>join (Not always)</li>\n<li>cogroup</li>\n<li>cartesian</li>\n<li>repartition</li>\n<li>repartitionAndSortWithPartitions</li>\n<li>coalesce</li>\n</ul>\n<p><em>例子</em></p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">sc.textFile(<span class=\"string\">\"someFile.txt\"</span>).</div><div class=\"line\">  map(mapFunc).</div><div class=\"line\">  flatMap(flatMapFunc).</div><div class=\"line\">  filter(filterFunc).</div><div class=\"line\">  count()</div></pre></td></tr></table></figure>\n<p>这段代码里，有一个action：count()，因此会产生一个job。这个job只包含一个stage，所有的tranformation都没有操作涉及到shuffle。</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">val</span> tokenized = sc.textFile(args(<span class=\"number\">0</span>)).flatMap(_.split(' '))</div><div class=\"line\"><span class=\"keyword\">val</span> wordCounts = tokenized.map((_, <span class=\"number\">1</span>)).reduceByKey(_ + _)</div><div class=\"line\"><span class=\"keyword\">val</span> filtered = wordCounts.filter(_._2 &gt;= <span class=\"number\">1000</span>)</div><div class=\"line\"><span class=\"keyword\">val</span> charCounts = filtered.flatMap(_._1.toCharArray).map((_, <span class=\"number\">1</span>)).</div><div class=\"line\">  reduceByKey(_ + _)</div><div class=\"line\">charCounts.collect()</div></pre></td></tr></table></figure>\n<p>这段代码有一个action：collect()。它有两个wide transformation: reduceByKey()， 这两个reduceByKey()操作把job划分为3个stage，第一个和第二个stage要做shuffle的操作。</p>\n<ol>\n<li>第一个stage：textFile –&gt; flatMap –&gt; map –&gt; reduceByKey</li>\n<li>第二个stage: filter –&gt; flatMap –&gt; map –&gt; reduceByKey</li>\n<li>第三个stage: count</li>\n</ol>\n<h2 id=\"正确的使用API\"><a href=\"#正确的使用API\" class=\"headerlink\" title=\"正确的使用API\"></a>正确的使用API</h2><p>条条大路通罗马，但不是每条道路都省时省心。在使用Spark的API进行数据运算时，往往有很多种做法，但不是每种做法都是高效的。</p>\n<p>总的原则：避免shuffle或者减少shuffle的数据量。</p>\n<ol>\n<li>在使用reduce能使数据减少的情况下，使用reduceBykey()而不是groupByKey()</li>\n</ol>\n<p>rdd.groupByKey().mapValues(<em>.sum) 会将整个RDD先shuffle然后再对每个partition的数据进行相加<br>rdd.reduceByKey(</em> + _) 会将每个partition的数据先加在一起，然后再shuffle</p>\n<p>这样能显著减少shuffle的数据量。但是如果reduce的算子不是 <em> + </em>， 而是某些让数据数量不变甚至增长的情况，则不适用。</p>\n<ol>\n<li>如果目标RDD的类型是一个集合类型，尽量使用mutable的集合类型</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">rdd.map(kv =&gt; (kv._1, new Set[String]() + kv._2))</div><div class=\"line\">    .reduceByKey(_ ++ _)</div></pre></td></tr></table></figure>\n<p>这种写法会为每一个map操作新建一个Set，非常损耗性能。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">val zero = new collection.mutable.Set[String]()</div><div class=\"line\">rdd.aggregateByKey(zero)(</div><div class=\"line\">    (set, v) =&gt; set += v,</div><div class=\"line\">    (set1, set2) =&gt; set1 ++= set2)</div></pre></td></tr></table></figure>\n<p>这种写法没有每次new一个Set的开销，更加高效。</p>\n<ol>\n<li>当数据量很少时，使用Broadcast而不是建成一个RDD。</li>\n</ol>\n<p>通常做法是把一个集合变成一个哈希表，然后广播到各个executor，然后在做Map操作时，直接通过Key来引用对应的值。</p>\n<h2 id=\"Partition对shuffle的影响\"><a href=\"#Partition对shuffle的影响\" class=\"headerlink\" title=\"Partition对shuffle的影响\"></a>Partition对shuffle的影响</h2><p>Spark总是竭尽所能减少shuffle的发生。例如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">rdd1 = someRdd.reduceByKey(...)</div><div class=\"line\">rdd2 = someOtherRdd.reduceByKey(...)</div><div class=\"line\">rdd3 = rdd1.join(rdd2)</div></pre></td></tr></table></figure>\n<p>如果没有优化，那么产生rdd1需要一次shuffle，产生rdd2需要一次shuffle，产生rdd3需要两次shuffle （rdd1和rdd2各自shuffle一次）</p>\n<p>rdd1和rdd2都使用reduceByKey()并且没有指定partitioner，那么他们使用的是默认的partitioner, 如果他们的partition数据也是一样的，<br>同样的key在两个RDD中都只能位于各自的某个partition中，rdd3的每个partition的数据都来源于rdd1和rdd2的一个partition。因此总共shuffle了两次。</p>\n<p>但是如果rdd1和rdd2两个的partition数目不一样，或者数据一样，但是他们的partitioner不一样，那么就总共需要三次次shuffle。<br>第一次: someRdd进行shuffle然后得到rdd1<br>第二次: someOtherRDD进行shuffle然后得到rdd2<br>第三次：将partition数目较少的RDD进行shuffle，使得和partition数据较多的RDD partition数目一样，然后再进行join。</p>\n<h1 id=\"优化2：合理分配计算资源\"><a href=\"#优化2：合理分配计算资源\" class=\"headerlink\" title=\"优化2：合理分配计算资源\"></a>优化2：合理分配计算资源</h1><p>除了尽量避免shuffle的产生或者减少shuffle的数据量，还需要为每个executor分配正确的资源。Spark管理的资源主要有CPU和内存。<br>对于网络和IO等资源，Spark并没有提供主动的管理。</p>\n<p>这里主要讲基于Yarn的资源分配。</p>\n<h2 id=\"CPU内核分配\"><a href=\"#CPU内核分配\" class=\"headerlink\" title=\"CPU内核分配\"></a>CPU内核分配</h2><p>Spark可以给每个executor指定其最大可以使用的CPU核数。</p>\n<p>有三个地方可以指定：</p>\n<ul>\n<li>spark-submit,spark-shell: –executor-cores</li>\n<li>spark-defaults.conf: spark.executor.cores</li>\n<li>SparkConf</li>\n</ul>\n<p>当Spark和Yarn结合时，Spark能申请的CPU资源还要受限于Yarn。</p>\n<p>yarn.nodemanager.resource.cpu-vcores 参数控制每个Yarn容器能使用的CPU数目。</p>\n<p>当Spark申请3个核时，实际上Spark是向Yarn申请了3个vcores.</p>\n<h2 id=\"内存分配\"><a href=\"#内存分配\" class=\"headerlink\" title=\"内存分配\"></a>内存分配</h2><p>有三个地方可以指定：</p>\n<ul>\n<li>spark-submit,spark-shell: –executor-memory</li>\n<li>spark-defaults.conf: spark.executor.memory</li>\n<li>SparkConf</li>\n</ul>\n<p>Spark向Yarn申请内存时比申请CPU要复杂。</p>\n<ul>\n<li>–executor-memory 控制的是executor的堆大小，但是每个executor还需要使用额外的内存空间来做缓存。</li>\n<li>spark.yarn.executor.memoryOverhead 用于控制向Yarn申请的额外的内存。它的默认值等于：max(384, 0.07 * spark.executor.memory)</li>\n<li>yarn.scheduler.minimum-allocation-mb 控制一个yarn容器最小分配的内存</li>\n</ul>\n<p><img src=\"/images/spark-tuning2-f1.png\" alt=\"Spark内存申请\"></p>\n<h2 id=\"分配原则\"><a href=\"#分配原则\" class=\"headerlink\" title=\"分配原则\"></a>分配原则</h2><ol>\n<li>Spark的application master也需要占用资源。在yarn-client模式下，默认占用1个CPU核和1G内存。在yarn-cluster模式下，application<br>master就是driver，由于application master同时也可能跑executor，因此要通过 –driver-memory 和 –driver-cores来为driver预留<br>足够的程序。</li>\n<li>不应该为一个executor分配太多的内存，这样反而会引起垃圾回收的延时。一般一个executor分配的内存最大不超过64G</li>\n<li>一个executor一般分配不超过5个CPU核心，太多的话可能会使得hadoop写入文件阻塞（希望后来没有这个问题 !)</li>\n<li>尽量不要分配一个executor只有一个CPU内核，然后在一台机器上创建很多个executor。主要有两个坏处：<ul>\n<li>broadcast是建立在executor上的，太多executor导致太多的广播变量</li>\n<li>每个executor都会占用一个额外的内存开销</li>\n</ul>\n</li>\n<li>永远要预留一个CPU内核和一定的内存供操作系统使用</li>\n</ol>\n<h2 id=\"实例\"><a href=\"#实例\" class=\"headerlink\" title=\"实例\"></a>实例</h2><p>假设一个集群有6台机器，每台机器有16核，64G内存，那么该如何分配资源呢？</p>\n<p>首先给yarn分配资源：</p>\n<p>yarn.nodemanager.resource.cpu-vcores 15<br>yarn.nodemanager.resource.memory-mb  63G</p>\n<p>要为系统进程预留1个核和1G的内存。</p>\n<p>然后给spark的executor分配CPU和内存。一种最直接的分配方案：</p>\n<p>–num-executors=6  –executor-cores=15 –executor-memory=63G</p>\n<p>也就是每天机器创建一个executor，每个executor占用15个核心，63G内存。但这是一个不可行的方案。首先每个executor分配15个核心，会导致HDFS<br>被阻塞，而且一个executor占用63G内存，加上额外的开销就超过63G了。</p>\n<p>一种优化的方案为：</p>\n<p>–num-executors=17  –executor-cores=5 –executor-memory=19</p>\n<ul>\n<li>每个executor占用5个核心。–executor-cores=5</li>\n<li>每个机器可以有 15 / 5 = 3 个executor, 6台机器一共可以创建18个executor，但是我们要除去application master， 因此共有18-1=17个executor</li>\n<li>每天机器上的3个executor，每个executor可以分配到 63 / 3 = 21 G内存，但是 21G应该是包含了额外的开销的，假设额外开销为 0.07 <em> X<br>0.07 </em> X + X = 21, X = 19.6, 向下舍去，为19G</li>\n</ul>\n<p>这样的分配不仅可以充分利用资源，而且一般不会出现内存溢出的情况。</p>\n<h1 id=\"优化三：使用更高效的数据存储\"><a href=\"#优化三：使用更高效的数据存储\" class=\"headerlink\" title=\"优化三：使用更高效的数据存储\"></a>优化三：使用更高效的数据存储</h1><p>例如使用parquet替代CSV，JSON，使用KryoSerializer替代默认的Java Serializer。这里不做重点介绍。</p>\n<h1 id=\"优化四：增加并行度\"><a href=\"#优化四：增加并行度\" class=\"headerlink\" title=\"优化四：增加并行度\"></a>优化四：增加并行度</h1><p>一般来说，在一个Stage里，task的数目和父亲RDD的partition数据是一样的 ，产生的子RDD的partition数目也是一样的。</p>\n<p>但是有些操作，可以改变子RDD的partition数目：</p>\n<ul>\n<li>coalesce可以将父亲RDD的分区数目压缩</li>\n<li>union操作产生的RDD分区数目是两个父亲RDD分区的和。</li>\n<li>catesian产生的RDD分区数据是两个父亲RDD分区的乘积。</li>\n</ul>\n<p>分区的数据，决定了Job并行执行的程度。如果有100机器，但是数据只有2个分区，那么一次就只有2个task在执行，其它机器都在空转。</p>\n<p>分区太少，会使得单个task要执行的数据过多，占用的时间和空间也较大。那么到底分多少个分区合适呢？</p>\n<p>第一种办法就是不断的尝试逼近：找到父亲RDD的分区数目，然后不断乘以1.5，知道发现性能无法获得提升为止。但是这种办法在显示中不太可行，<br>因为你不太可能一次次的去跑同样的job。</p>\n<p>另外一种尝试就是，根据系统的CPU，内存结合程序的特点来大概计算，但是很难量化。</p>\n<p>总的原则就是：多些分区要比少分区要好，因为在spark里创建task是很便宜的。</p>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li><a href=\"http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-1/\">http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-1/</a></li>\n<li><a href=\"http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-2/\">http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-2/</a></li>\n</ul>\n"},{"title":"Spark学习资源","date":"2016-11-21T02:44:15.000Z","_content":"\n**持续更新中...**\n\n# Gitbook\n\n[Databricks Knowledge Base](https://databricks.gitbooks.io/databricks-spark-knowledge-base/content/index.html)\n[Mastering Apache Spark 2.0](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/)\n\n# 网站\n\n[Spark官网](http://spark.apache.org/)\n\n# 视频\n\n\n\n\n\n","source":"_posts/spark-resources.md","raw":"---\ntitle: Spark学习资源\ndate: 2016-11-21 10:44:15\ntags: \n - Spark\n - Resource\n---\n\n**持续更新中...**\n\n# Gitbook\n\n[Databricks Knowledge Base](https://databricks.gitbooks.io/databricks-spark-knowledge-base/content/index.html)\n[Mastering Apache Spark 2.0](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/)\n\n# 网站\n\n[Spark官网](http://spark.apache.org/)\n\n# 视频\n\n\n\n\n\n","slug":"spark-resources","published":1,"updated":"2016-11-21T03:15:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civt4av1o0007s4kbggf3p26k","content":"<p><strong>持续更新中…</strong></p>\n<h1 id=\"Gitbook\"><a href=\"#Gitbook\" class=\"headerlink\" title=\"Gitbook\"></a>Gitbook</h1><p><a href=\"https://databricks.gitbooks.io/databricks-spark-knowledge-base/content/index.html\" target=\"_blank\" rel=\"external\">Databricks Knowledge Base</a><br><a href=\"https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/\" target=\"_blank\" rel=\"external\">Mastering Apache Spark 2.0</a></p>\n<h1 id=\"网站\"><a href=\"#网站\" class=\"headerlink\" title=\"网站\"></a>网站</h1><p><a href=\"http://spark.apache.org/\" target=\"_blank\" rel=\"external\">Spark官网</a></p>\n<h1 id=\"视频\"><a href=\"#视频\" class=\"headerlink\" title=\"视频\"></a>视频</h1>","excerpt":"","more":"<p><strong>持续更新中…</strong></p>\n<h1 id=\"Gitbook\"><a href=\"#Gitbook\" class=\"headerlink\" title=\"Gitbook\"></a>Gitbook</h1><p><a href=\"https://databricks.gitbooks.io/databricks-spark-knowledge-base/content/index.html\">Databricks Knowledge Base</a><br><a href=\"https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/\">Mastering Apache Spark 2.0</a></p>\n<h1 id=\"网站\"><a href=\"#网站\" class=\"headerlink\" title=\"网站\"></a>网站</h1><p><a href=\"http://spark.apache.org/\">Spark官网</a></p>\n<h1 id=\"视频\"><a href=\"#视频\" class=\"headerlink\" title=\"视频\"></a>视频</h1>"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"civt4av140000s4kby9pmg6jv","tag_id":"civt4av1e0002s4kb1q60uz9c","_id":"civt4av1o0009s4kbzb5146bd"},{"post_id":"civt4av140000s4kby9pmg6jv","tag_id":"civt4av1o0006s4kbdu2o65xl","_id":"civt4av1o000as4kbfchh7zfo"},{"post_id":"civt4av1e0001s4kbmly4mds2","tag_id":"civt4av1o0008s4kb6vw9rq4h","_id":"civt4av1y000cs4kbhcjaiuaz"},{"post_id":"civt4av1o0004s4kb36nt76y1","tag_id":"civt4av1o000bs4kbxeipb9a6","_id":"civt4av1y000gs4kbgv9xbus7"},{"post_id":"civt4av1o0004s4kb36nt76y1","tag_id":"civt4av1y000ds4kblyv2kxxp","_id":"civt4av1y000hs4kbemy9twik"},{"post_id":"civt4av1o0004s4kb36nt76y1","tag_id":"civt4av1y000es4kbosxzqvcj","_id":"civt4av1y000js4kbavo5s0ci"},{"post_id":"civt4av1o0005s4kbe52zd5fa","tag_id":"civt4av1y000fs4kbrfs98x9b","_id":"civt4av1y000ks4kb8v6gl359"},{"post_id":"civt4av1o0007s4kbggf3p26k","tag_id":"civt4av1y000fs4kbrfs98x9b","_id":"civt4av1y000ms4kbspgmeisi"},{"post_id":"civt4av1o0007s4kbggf3p26k","tag_id":"civt4av1y000ls4kb7wgnfg9w","_id":"civt4av1y000ns4kb6nvezqcg"}],"Tag":[{"name":"股票","_id":"civt4av1e0002s4kb1q60uz9c"},{"name":"MACD","_id":"civt4av1o0006s4kbdu2o65xl"},{"name":"Tool","_id":"civt4av1o0008s4kb6vw9rq4h"},{"name":"python","_id":"civt4av1o000bs4kbxeipb9a6"},{"name":"scikit-learn","_id":"civt4av1y000ds4kblyv2kxxp"},{"name":"机器学习","_id":"civt4av1y000es4kbosxzqvcj"},{"name":"Spark","_id":"civt4av1y000fs4kbrfs98x9b"},{"name":"Resource","_id":"civt4av1y000ls4kb7wgnfg9w"}]}}